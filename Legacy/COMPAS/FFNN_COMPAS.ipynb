{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ATH=\"/content/drive/My Drive/Kandidat speciale/500 - Notebooks/models/all races_CV50/\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## AIR ### "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["AIR=True"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["file_name=\"COMPAS_dataset_OHE_std.csv\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["full_file_path=\"/restricted/s164512/G2020-57-Aalborg-bias/COMPAS/Data/\"+file_name"]}, {"cell_type": "markdown", "metadata": {}, "source": ["itel_mitigation=\"original\"<br>\n", "itel_mitigation=\"DroppingD\"<br>\n", "itel_mitigation=\"Gender Swap\"<br>\n", "itel_mitigation=\"DI remove\"<br>\n", "itel_mitigation=\"LFR\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["titel_mitigation=\"COMPAS\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PATH_orig=\"/restricted/s164512/G2020-57-Aalborg-bias/lau/FFNN_ohe/models/\"+titel_mitigation+\"/\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dropping_D=True\n", "gender_swap=False\n", "DI_remove=False\n", "LFR_mitigation=False #S\u00c3\u00a6t droppingD=True, men ikke fjern den fra X"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_col_name=\"is_recid\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_col_names=['sex',\n", "'age',\n", "'juv_fel_count',\n", "'juv_misd_count',\n", "'juv_other_count',\n", "'priors_count',\n", "'race_African-American',\n", "'race_Asian',\n", "'race_Caucasian',\n", "'race_Hispanic',\n", "'race_Native American',\n", "'race_Other',\n", "'c_charge_desc_Abuse Without Great Harm',\n", "'c_charge_desc_Accessory After the Fact',\n", "'c_charge_desc_Agg Abuse Elderlly/Disabled Adult',\n", "'c_charge_desc_Agg Assault Law Enforc Officer',\n", "'c_charge_desc_Agg Assault W/int Com Fel Dome',\n", "'c_charge_desc_Agg Battery Grt/Bod/Harm',\n", "'c_charge_desc_Agg Fleeing and Eluding',\n", "'c_charge_desc_Agg Fleeing/Eluding High Speed',\n", "'c_charge_desc_Aggr Child Abuse-Torture,Punish',\n", "'c_charge_desc_Aggrav Battery w/Deadly Weapon',\n", "'c_charge_desc_Aggrav Child Abuse-Agg Battery',\n", "'c_charge_desc_Aggrav Child Abuse-Causes Harm',\n", "'c_charge_desc_Aggrav Stalking After Injunctn',\n", "'c_charge_desc_Aggravated Assault',\n", "'c_charge_desc_Aggravated Assault W/Dead Weap',\n", "'c_charge_desc_Aggravated Assault W/dead Weap',\n", "'c_charge_desc_Aggravated Assault W/o Firearm',\n", "'c_charge_desc_Aggravated Assault w/Firearm',\n", "'c_charge_desc_Aggravated Battery',\n", "'c_charge_desc_Aggravated Battery (Firearm)',\n", "'c_charge_desc_Aggravated Battery (Firearm/Actual Possession)',\n", "'c_charge_desc_Aggravated Battery / Pregnant',\n", "'c_charge_desc_Aggravated Battery On 65/Older',\n", "'c_charge_desc_Aggress/Panhandle/Beg/Solict',\n", "'c_charge_desc_Aide/Abet Prostitution Lewdness',\n", "'c_charge_desc_Aiding Escape',\n", "'c_charge_desc_Alcoholic Beverage Violation-FL',\n", "'c_charge_desc_Armed Trafficking in Cannabis',\n", "'c_charge_desc_Arson II (Vehicle)',\n", "'c_charge_desc_Arson in the First Degree',\n", "'c_charge_desc_Assault',\n", "'c_charge_desc_Assault Law Enforcement Officer',\n", "'c_charge_desc_Att Burgl Conv Occp',\n", "'c_charge_desc_Att Burgl Struc/Conv Dwel/Occp',\n", "'c_charge_desc_Att Burgl Unoccupied Dwel',\n", "'c_charge_desc_Att Tamper w/Physical Evidence',\n", "'c_charge_desc_Attempt Armed Burglary Dwell',\n", "'c_charge_desc_Attempt Burglary (Struct)',\n", "'c_charge_desc_Attempted Burg/Convey/Unocc',\n", "'c_charge_desc_Attempted Burg/struct/unocc',\n", "'c_charge_desc_Attempted Deliv Control Subst',\n", "'c_charge_desc_Attempted Robbery  No Weapon',\n", "'c_charge_desc_Attempted Robbery  Weapon',\n", "'c_charge_desc_Attempted Robbery Firearm',\n", "'c_charge_desc_Battery',\n", "'c_charge_desc_Battery Emergency Care Provide',\n", "'c_charge_desc_Battery On A Person Over 65',\n", "'c_charge_desc_Battery On Fire Fighter',\n", "'c_charge_desc_Battery On Parking Enfor Speci',\n", "'c_charge_desc_Battery Spouse Or Girlfriend',\n", "'c_charge_desc_Battery on Law Enforc Officer',\n", "'c_charge_desc_Battery on a Person Over 65',\n", "'c_charge_desc_Bribery Athletic Contests',\n", "'c_charge_desc_Burgl Dwel/Struct/Convey Armed',\n", "'c_charge_desc_Burglary Assault/Battery Armed',\n", "'c_charge_desc_Burglary Conveyance Armed',\n", "'c_charge_desc_Burglary Conveyance Assault/Bat',\n", "'c_charge_desc_Burglary Conveyance Occupied',\n", "'c_charge_desc_Burglary Conveyance Unoccup',\n", "'c_charge_desc_Burglary Dwelling Armed',\n", "'c_charge_desc_Burglary Dwelling Assault/Batt',\n", "'c_charge_desc_Burglary Dwelling Occupied',\n", "'c_charge_desc_Burglary Structure Assault/Batt',\n", "'c_charge_desc_Burglary Structure Occupied',\n", "'c_charge_desc_Burglary Structure Unoccup',\n", "'c_charge_desc_Burglary Unoccupied Dwelling',\n", "'c_charge_desc_Burglary With Assault/battery',\n", "'c_charge_desc_Carjacking w/o Deadly Weapon',\n", "'c_charge_desc_Carjacking with a Firearm',\n", "'c_charge_desc_Carry Open/Uncov Bev In Pub',\n", "'c_charge_desc_Carrying A Concealed Weapon',\n", "'c_charge_desc_Carrying Concealed Firearm',\n", "'c_charge_desc_Cash Item w/Intent to Defraud',\n", "'c_charge_desc_Cause Anoth Phone Ring Repeat',\n", "'c_charge_desc_Child Abuse',\n", "'c_charge_desc_Compulsory Attendance Violation',\n", "'c_charge_desc_Compulsory Sch Attnd Violation',\n", "'c_charge_desc_Computer Pornography',\n", "'c_charge_desc_Consp Traff Oxycodone  4g><14g',\n", "'c_charge_desc_Consp Traff Oxycodone 28g><30k',\n", "'c_charge_desc_Conspiracy Dealing Stolen Prop',\n", "'c_charge_desc_Conspiracy to Deliver Cocaine',\n", "'c_charge_desc_Consume Alcoholic Bev Pub',\n", "'c_charge_desc_Contradict Statement',\n", "'c_charge_desc_Contribute Delinquency Of A Minor',\n", "'c_charge_desc_Corrupt Public Servant',\n", "'c_charge_desc_Counterfeit Lic Plates/Sticker',\n", "'c_charge_desc_Crim Attempt/Solic/Consp',\n", "'c_charge_desc_Crim Attempt/Solicit/Consp',\n", "'c_charge_desc_Crim Use Of Personal Id Info',\n", "'c_charge_desc_Crim Use of Personal ID Info',\n", "'c_charge_desc_Crimin Mischief Damage $1000+',\n", "'c_charge_desc_Criminal Attempt 3rd Deg Felon',\n", "'c_charge_desc_Criminal Mischief',\n", "'c_charge_desc_Criminal Mischief Damage <$200',\n", "'c_charge_desc_Criminal Mischief>$200<$1000',\n", "'c_charge_desc_Crlty Twrd Child Urge Oth Act',\n", "'c_charge_desc_Cruelty Toward Child',\n", "'c_charge_desc_Cruelty to Animals',\n", "'c_charge_desc_Culpable Negligence',\n", "'c_charge_desc_D.U.I. Serious Bodily Injury',\n", "'c_charge_desc_DOC/Cause Public Danger',\n", "'c_charge_desc_DUI - Enhanced',\n", "'c_charge_desc_DUI - Property Damage/Personal Injury',\n", "'c_charge_desc_DUI Blood Alcohol Above 0.20',\n", "'c_charge_desc_DUI Level 0.15 Or Minor In Veh',\n", "'c_charge_desc_DUI Property Damage/Injury',\n", "'c_charge_desc_DUI- Enhanced',\n", "'c_charge_desc_DUI/Property Damage/Persnl Inj',\n", "'c_charge_desc_DWI w/Inj Susp Lic / Habit Off',\n", "'c_charge_desc_DWLS Canceled Disqul 1st Off',\n", "'c_charge_desc_DWLS Susp/Cancel Revoked',\n", "'c_charge_desc_Dealing In Stolen Property',\n", "'c_charge_desc_Dealing in Stolen Property',\n", "'c_charge_desc_Defrauding Innkeeper',\n", "'c_charge_desc_Defrauding Innkeeper $300/More',\n", "'c_charge_desc_Del 3,4 Methylenedioxymethcath',\n", "'c_charge_desc_Del Cannabis At/Near Park',\n", "'c_charge_desc_Del Cannabis For Consideration',\n", "'c_charge_desc_Del Morphine at/near Park',\n", "'c_charge_desc_Del of JWH-250 2-Methox 1-Pentyl',\n", "'c_charge_desc_Deliver 3,4 Methylenediox',\n", "'c_charge_desc_Deliver Alprazolam',\n", "'c_charge_desc_Deliver Cannabis',\n", "'c_charge_desc_Deliver Cannabis 1000FTSch',\n", "'c_charge_desc_Deliver Cocaine',\n", "'c_charge_desc_Deliver Cocaine 1000FT Church',\n", "'c_charge_desc_Deliver Cocaine 1000FT Park',\n", "'c_charge_desc_Deliver Cocaine 1000FT School',\n", "'c_charge_desc_Deliver Cocaine 1000FT Store',\n", "'c_charge_desc_Delivery Of Drug Paraphernalia',\n", "'c_charge_desc_Delivery of 5-Fluoro PB-22',\n", "'c_charge_desc_Delivery of Heroin',\n", "'c_charge_desc_Depriv LEO of Protect/Communic',\n", "'c_charge_desc_Discharge Firearm From Vehicle',\n", "'c_charge_desc_Disorderly Conduct',\n", "'c_charge_desc_Disorderly Intoxication',\n", "'c_charge_desc_Disrupting School Function',\n", "'c_charge_desc_Drivg While Lic Suspd/Revk/Can',\n", "'c_charge_desc_Driving License Suspended',\n", "'c_charge_desc_Driving Under The Influence',\n", "'c_charge_desc_Driving While License Revoked',\n", "'c_charge_desc_Escape',\n", "'c_charge_desc_Exhibition Weapon School Prop',\n", "'c_charge_desc_Expired DL More Than 6 Months',\n", "'c_charge_desc_Exploit Elderly Person 20-100K',\n", "'c_charge_desc_Exposes Culpable Negligence',\n", "'c_charge_desc_Extradition/Defendants',\n", "'c_charge_desc_Fabricating Physical Evidence',\n", "'c_charge_desc_Fail Obey Driv Lic Restrictions',\n", "'c_charge_desc_Fail Register Career Offender',\n", "'c_charge_desc_Fail Register Vehicle',\n", "'c_charge_desc_Fail Sex Offend Report Bylaw',\n", "'c_charge_desc_Fail To Obey Police Officer',\n", "'c_charge_desc_Fail To Redeliv Hire/Leas Prop',\n", "'c_charge_desc_Fail To Redeliver Hire Prop',\n", "'c_charge_desc_Fail To Secure Load',\n", "'c_charge_desc_Failure To Pay Taxi Cab Charge',\n", "'c_charge_desc_Failure To Return Hired Vehicle',\n", "'c_charge_desc_False 911 Call',\n", "'c_charge_desc_False Bomb Report',\n", "'c_charge_desc_False Imprisonment',\n", "'c_charge_desc_False Info LEO During Invest',\n", "'c_charge_desc_False Motor Veh Insurance Card',\n", "'c_charge_desc_False Name By Person Arrest',\n", "'c_charge_desc_False Ownership Info/Pawn Item',\n", "'c_charge_desc_Falsely Impersonating Officer',\n", "'c_charge_desc_Fel Drive License Perm Revoke',\n", "'c_charge_desc_Felon in Pos of Firearm or Amm',\n", "'c_charge_desc_Felony Batt(Great Bodily Harm)',\n", "'c_charge_desc_Felony Battery',\n", "'c_charge_desc_Felony Battery (Dom Strang)',\n", "'c_charge_desc_Felony Battery w/Prior Convict',\n", "'c_charge_desc_Felony Committing Prostitution',\n", "'c_charge_desc_Felony DUI (level 3)',\n", "'c_charge_desc_Felony DUI - Enhanced',\n", "'c_charge_desc_Felony Driving While Lic Suspd',\n", "'c_charge_desc_Felony Petit Theft',\n", "'c_charge_desc_Felony/Driving Under Influence',\n", "'c_charge_desc_Fighting/Baiting Animals',\n", "'c_charge_desc_Flee/Elude LEO-Agg Flee Unsafe',\n", "'c_charge_desc_Fleeing Or Attmp Eluding A Leo',\n", "'c_charge_desc_Fleeing or Eluding a LEO',\n", "'c_charge_desc_Forging Bank Bills/Promis Note',\n", "'c_charge_desc_Fraud Obtain Food or Lodging',\n", "'c_charge_desc_Fraudulent Use of Credit Card',\n", "'c_charge_desc_Gambling/Gamb Paraphernalia',\n", "'c_charge_desc_Giving False Crime Report',\n", "'c_charge_desc_Grand Theft (Motor Vehicle)',\n", "'c_charge_desc_Grand Theft (motor Vehicle)',\n", "'c_charge_desc_Grand Theft Dwell Property',\n", "'c_charge_desc_Grand Theft Firearm',\n", "'c_charge_desc_Grand Theft In The 3Rd Degree',\n", "'c_charge_desc_Grand Theft in the 1st Degree',\n", "'c_charge_desc_Grand Theft in the 3rd Degree',\n", "'c_charge_desc_Grand Theft of a Fire Extinquisher',\n", "'c_charge_desc_Grand Theft of the 2nd Degree',\n", "'c_charge_desc_Grand Theft on 65 Yr or Older',\n", "'c_charge_desc_Harass Witness/Victm/Informnt',\n", "'c_charge_desc_Harm Public Servant Or Family',\n", "'c_charge_desc_Hiring with Intent to Defraud',\n", "'c_charge_desc_Imperson Public Officer or Emplyee',\n", "'c_charge_desc_Insurance Fraud',\n", "'c_charge_desc_Interfere W/Traf Cont Dev RR',\n", "'c_charge_desc_Interference with Custody',\n", "'c_charge_desc_Intoxicated/Safety Of Another',\n", "'c_charge_desc_Introduce Contraband Into Jail',\n", "'c_charge_desc_Issuing a Worthless Draft',\n", "'c_charge_desc_Kidnapping / Domestic Violence',\n", "'c_charge_desc_Lease For Purpose Trafficking',\n", "'c_charge_desc_Leave Acc/Attend Veh/More $50',\n", "'c_charge_desc_Leave Accd/Attend Veh/Less $50',\n", "'c_charge_desc_Leaving Acc/Unattended Veh',\n", "'c_charge_desc_Leaving the Scene of Accident',\n", "'c_charge_desc_Lewd Act Presence Child 16-',\n", "'c_charge_desc_Lewd or Lascivious Molestation',\n", "'c_charge_desc_Lewd/Lasc Battery Pers 12+/<16',\n", "'c_charge_desc_Lewd/Lasc Exhib Presence <16yr',\n", "'c_charge_desc_Lewd/Lasciv Molest Elder Persn',\n", "'c_charge_desc_Lewdness Violation',\n", "'c_charge_desc_License Suspended Revoked',\n", "'c_charge_desc_Littering',\n", "'c_charge_desc_Live on Earnings of Prostitute',\n", "'c_charge_desc_Lve/Scen/Acc/Veh/Prop/Damage',\n", "'c_charge_desc_Manage Busn W/O City Occup Lic',\n", "'c_charge_desc_Manslaughter W/Weapon/Firearm',\n", "'c_charge_desc_Manufacture Cannabis',\n", "'c_charge_desc_Misuse Of 911 Or E911 System',\n", "'c_charge_desc_Money Launder 100K or More Dols',\n", "'c_charge_desc_Murder In 2nd Degree W/firearm',\n", "'c_charge_desc_Murder in 2nd Degree',\n", "'c_charge_desc_Murder in the First Degree',\n", "'c_charge_desc_Neglect Child / Bodily Harm',\n", "'c_charge_desc_Neglect Child / No Bodily Harm',\n", "'c_charge_desc_Neglect/Abuse Elderly Person',\n", "'c_charge_desc_Obstruct Fire Equipment',\n", "'c_charge_desc_Obstruct Officer W/Violence',\n", "'c_charge_desc_Obtain Control Substance By Fraud',\n", "'c_charge_desc_Offer Agree Secure For Lewd Act',\n", "'c_charge_desc_Offer Agree Secure/Lewd Act',\n", "'c_charge_desc_Offn Against Intellectual Prop',\n", "'c_charge_desc_Open Carrying Of Weapon',\n", "'c_charge_desc_Oper Motorcycle W/O Valid DL',\n", "'c_charge_desc_Operating W/O Valid License',\n", "'c_charge_desc_Opert With Susp DL 2ND Offense',\n", "'c_charge_desc_Opert With Susp DL 2nd Offens',\n", "'c_charge_desc_PL/Unlaw Use Credit Card',\n", "'c_charge_desc_Petit Theft',\n", "'c_charge_desc_Petit Theft $100- $300',\n", "'c_charge_desc_Pos Cannabis For Consideration',\n", "'c_charge_desc_Pos Cannabis W/Intent Sel/Del',\n", "'c_charge_desc_Pos Methylenedioxymethcath W/I/D/S',\n", "'c_charge_desc_Poss 3,4 MDMA (Ecstasy)',\n", "'c_charge_desc_Poss Alprazolam W/int Sell/Del',\n", "'c_charge_desc_Poss Anti-Shoplifting Device',\n", "'c_charge_desc_Poss Cntrft Contr Sub w/Intent',\n", "'c_charge_desc_Poss Cocaine/Intent To Del/Sel',\n", "'c_charge_desc_Poss Contr Subst W/o Prescript',\n", "'c_charge_desc_Poss Counterfeit Payment Inst',\n", "'c_charge_desc_Poss Drugs W/O A Prescription',\n", "'c_charge_desc_Poss F/Arm Delinq',\n", "'c_charge_desc_Poss Firearm W/Altered ID#',\n", "'c_charge_desc_Poss Meth/Diox/Meth/Amp (MDMA)',\n", "'c_charge_desc_Poss Of 1,4-Butanediol',\n", "'c_charge_desc_Poss Of Controlled Substance',\n", "'c_charge_desc_Poss Of RX Without RX',\n", "'c_charge_desc_Poss Oxycodone W/Int/Sell/Del',\n", "'c_charge_desc_Poss Pyrrolidinobutiophenone',\n", "'c_charge_desc_Poss Pyrrolidinovalerophenone',\n", "'c_charge_desc_Poss Pyrrolidinovalerophenone W/I/D/S',\n", "'c_charge_desc_Poss Similitude of Drivers Lic',\n", "'c_charge_desc_Poss Tetrahydrocannabinols',\n", "'c_charge_desc_Poss Trifluoromethylphenylpipe',\n", "'c_charge_desc_Poss Unlaw Issue Driver Licenc',\n", "'c_charge_desc_Poss Unlaw Issue Id',\n", "'c_charge_desc_Poss Wep Conv Felon',\n", "'c_charge_desc_Poss of Cocaine W/I/D/S 1000FT Park',\n", "'c_charge_desc_Poss of Firearm by Convic Felo',\n", "'c_charge_desc_Poss of Methylethcathinone',\n", "'c_charge_desc_Poss of Vessel w/Altered ID NO',\n", "'c_charge_desc_Poss/Sell/Del Cocaine 1000FT Sch',\n", "'c_charge_desc_Poss/Sell/Del/Man Amobarbital',\n", "'c_charge_desc_Poss/Sell/Deliver Clonazepam',\n", "'c_charge_desc_Poss/pur/sell/deliver Cocaine',\n", "'c_charge_desc_Poss3,4 Methylenedioxymethcath',\n", "'c_charge_desc_Posses/Disply Susp/Revk/Frd DL',\n", "'c_charge_desc_Possess Cannabis 1000FTSch',\n", "'c_charge_desc_Possess Cannabis/20 Grams Or Less',\n", "'c_charge_desc_Possess Controlled Substance',\n", "'c_charge_desc_Possess Countrfeit Credit Card',\n", "'c_charge_desc_Possess Drug Paraphernalia',\n", "'c_charge_desc_Possess Mot Veh W/Alt Vin #',\n", "'c_charge_desc_Possess Tobacco Product Under 18',\n", "'c_charge_desc_Possess Weapon On School Prop',\n", "'c_charge_desc_Possess w/I/Utter Forged Bills',\n", "'c_charge_desc_Possess/Use Weapon 1 Deg Felon',\n", "'c_charge_desc_Possession Burglary Tools',\n", "'c_charge_desc_Possession Child Pornography',\n", "'c_charge_desc_Possession Firearm School Prop',\n", "'c_charge_desc_Possession Of 3,4Methylenediox',\n", "'c_charge_desc_Possession Of Alprazolam',\n", "'c_charge_desc_Possession Of Amphetamine',\n", "'c_charge_desc_Possession Of Anabolic Steroid',\n", "'c_charge_desc_Possession Of Buprenorphine',\n", "'c_charge_desc_Possession Of Carisoprodol',\n", "'c_charge_desc_Possession Of Clonazepam',\n", "'c_charge_desc_Possession Of Cocaine',\n", "'c_charge_desc_Possession Of Diazepam',\n", "'c_charge_desc_Possession Of Fentanyl',\n", "'c_charge_desc_Possession Of Heroin',\n", "'c_charge_desc_Possession Of Lorazepam',\n", "'c_charge_desc_Possession Of Methamphetamine',\n", "'c_charge_desc_Possession Of Paraphernalia',\n", "'c_charge_desc_Possession Of Phentermine',\n", "'c_charge_desc_Possession of Alcohol Under 21',\n", "'c_charge_desc_Possession of Benzylpiperazine',\n", "'c_charge_desc_Possession of Butylone',\n", "'c_charge_desc_Possession of Cannabis',\n", "'c_charge_desc_Possession of Cocaine',\n", "'c_charge_desc_Possession of Codeine',\n", "'c_charge_desc_Possession of Ethylone',\n", "'c_charge_desc_Possession of Hydrocodone',\n", "'c_charge_desc_Possession of Hydromorphone',\n", "'c_charge_desc_Possession of LSD',\n", "'c_charge_desc_Possession of Methadone',\n", "'c_charge_desc_Possession of Morphine',\n", "'c_charge_desc_Possession of Oxycodone',\n", "'c_charge_desc_Possession of XLR11',\n", "'c_charge_desc_Present Proof of Invalid Insur',\n", "'c_charge_desc_Principal In The First Degree',\n", "'c_charge_desc_Prostitution',\n", "'c_charge_desc_Prostitution/Lewd Act Assignation',\n", "'c_charge_desc_Prostitution/Lewdness/Assign',\n", "'c_charge_desc_Prowling/Loitering',\n", "'c_charge_desc_Purchase Cannabis',\n", "'c_charge_desc_Purchase Of Cocaine',\n", "'c_charge_desc_Purchase/P/W/Int Cannabis',\n", "'c_charge_desc_Purchasing Of Alprazolam',\n", "'c_charge_desc_Reckless Driving',\n", "'c_charge_desc_Refuse Submit Blood/Breath Test',\n", "'c_charge_desc_Refuse to Supply DNA Sample',\n", "'c_charge_desc_Resist Officer w/Violence',\n", "'c_charge_desc_Resist/Obstruct W/O Violence',\n", "'c_charge_desc_Restraining Order Dating Viol',\n", "'c_charge_desc_Retail Theft $300 1st Offense',\n", "'c_charge_desc_Retail Theft $300 2nd Offense',\n", "'c_charge_desc_Ride Tri-Rail Without Paying',\n", "'c_charge_desc_Robbery / No Weapon',\n", "'c_charge_desc_Robbery / Weapon',\n", "'c_charge_desc_Robbery Sudd Snatch No Weapon',\n", "'c_charge_desc_Robbery W/Deadly Weapon',\n", "'c_charge_desc_Robbery W/Firearm',\n", "'c_charge_desc_Sale/Del Cannabis At/Near Scho',\n", "'c_charge_desc_Sale/Del Counterfeit Cont Subs',\n", "'c_charge_desc_Sel Etc/Pos/w/Int Contrft Schd',\n", "'c_charge_desc_Sel/Pur/Mfr/Del Control Substa',\n", "'c_charge_desc_Sell Cannabis',\n", "'c_charge_desc_Sell Conterfeit Cont Substance',\n", "'c_charge_desc_Sell or Offer for Sale Counterfeit Goods',\n", "'c_charge_desc_Sell/Man/Del Pos/w/int Heroin',\n", "'c_charge_desc_Sex Batt Faml/Cust Vict 12-17Y',\n", "'c_charge_desc_Sex Battery Deft 18+/Vict 11-',\n", "'c_charge_desc_Sex Offender Fail Comply W/Law',\n", "'c_charge_desc_Sexual Battery / Vict 12 Yrs +',\n", "'c_charge_desc_Sexual Performance by a Child',\n", "'c_charge_desc_Shoot In Occupied Dwell',\n", "'c_charge_desc_Shoot Into Vehicle',\n", "'c_charge_desc_Simulation of Legal Process',\n", "'c_charge_desc_Solic to Commit Battery',\n", "'c_charge_desc_Solicit Deliver Cocaine',\n", "'c_charge_desc_Solicit Purchase Cocaine',\n", "'c_charge_desc_Solicit To Deliver Cocaine',\n", "'c_charge_desc_Solicitation On Felony 3 Deg',\n", "'c_charge_desc_Soliciting For Prostitution',\n", "'c_charge_desc_Sound Articles Over 100',\n", "'c_charge_desc_Stalking',\n", "'c_charge_desc_Stalking (Aggravated)',\n", "'c_charge_desc_Strong Armed  Robbery',\n", "'c_charge_desc_Structuring Transactions',\n", "'c_charge_desc_Susp Drivers Lic 1st Offense',\n", "'c_charge_desc_Tamper With Victim',\n", "'c_charge_desc_Tamper With Witness',\n", "'c_charge_desc_Tamper With Witness/Victim/CI',\n", "'c_charge_desc_Tampering With Physical Evidence',\n", "'c_charge_desc_Tampering with a Victim',\n", "'c_charge_desc_Theft',\n", "'c_charge_desc_Theft/To Deprive',\n", "'c_charge_desc_Threat Public Servant',\n", "'c_charge_desc_Throw Deadly Missile Into Veh',\n", "'c_charge_desc_Throw In Occupied Dwell',\n", "'c_charge_desc_Throw Missile Into Pub/Priv Dw',\n", "'c_charge_desc_Traff In Cocaine <400g>150 Kil',\n", "'c_charge_desc_Traffic Counterfeit Cred Cards',\n", "'c_charge_desc_Traffick Amphetamine 28g><200g',\n", "'c_charge_desc_Traffick Hydrocodone   4g><14g',\n", "'c_charge_desc_Traffick Oxycodone     4g><14g',\n", "'c_charge_desc_Trans/Harm/Material to a Minor',\n", "'c_charge_desc_Trespass On School Grounds',\n", "'c_charge_desc_Trespass Other Struct/Conve',\n", "'c_charge_desc_Trespass Private Property',\n", "'c_charge_desc_Trespass Property w/Dang Weap',\n", "'c_charge_desc_Trespass Struct/Convey Occupy',\n", "'c_charge_desc_Trespass Struct/Conveyance',\n", "'c_charge_desc_Trespass Structure w/Dang Weap',\n", "'c_charge_desc_Trespass Structure/Conveyance',\n", "'c_charge_desc_Trespassing/Construction Site',\n", "'c_charge_desc_Tresspass Struct/Conveyance',\n", "'c_charge_desc_Tresspass in Structure or Conveyance',\n", "'c_charge_desc_Unauth C/P/S Sounds>1000/Audio',\n", "'c_charge_desc_Unauth Poss ID Card or DL',\n", "'c_charge_desc_Unauthorized Interf w/Railroad',\n", "'c_charge_desc_Unemployment Compensatn Fraud',\n", "'c_charge_desc_Unl/Disturb Education/Instui',\n", "'c_charge_desc_Unlaw Lic Use/Disply Of Others',\n", "'c_charge_desc_Unlaw LicTag/Sticker Attach',\n", "'c_charge_desc_Unlaw Use False Name/Identity',\n", "'c_charge_desc_Unlawful Conveyance of Fuel',\n", "'c_charge_desc_Unlawful Use Of Police Badges',\n", "'c_charge_desc_Unlicensed Telemarketing',\n", "'c_charge_desc_Use Computer for Child Exploit',\n", "'c_charge_desc_Use Of 2 Way Device To Fac Fel',\n", "'c_charge_desc_Use Scanning Device to Defraud',\n", "'c_charge_desc_Use of Anti-Shoplifting Device',\n", "'c_charge_desc_Uttering Forged Bills',\n", "'c_charge_desc_Uttering Forged Credit Card',\n", "'c_charge_desc_Uttering Worthless Check +$150',\n", "'c_charge_desc_Uttering a Forged Instrument',\n", "'c_charge_desc_Video Voyeur-<24Y on Child >16',\n", "'c_charge_desc_Viol Injunct Domestic Violence',\n", "'c_charge_desc_Viol Injunction Protect Dom Vi',\n", "'c_charge_desc_Viol Pretrial Release Dom Viol',\n", "'c_charge_desc_Viol Prot Injunc Repeat Viol',\n", "'c_charge_desc_Violation License Restrictions',\n", "'c_charge_desc_Violation Of Boater Safety Id',\n", "'c_charge_desc_Violation of Injunction Order/Stalking/Cyberstalking',\n", "'c_charge_desc_Voyeurism',\n", "'c_charge_desc_arrest case no charge',\n", "'c_charge_degree_F',\n", "'c_charge_degree_M']\n", "#X_col_names = [col for col in X_col_names if col not in leave_out ]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["procted_col_name=\"race\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### COMPASS ####"]}, {"cell_type": "markdown", "metadata": {}, "source": ["IR=False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["itel_mitigation=\"testCOMPAS\"<br>\n", "ATH_orig=\"/restricted/s164512/G2020-57-Aalborg-bias/lau/FFNN/models/\"+titel_mitigation+\"/\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["ull_file_path = 'https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_col_name=\"is_recid\"<br>\n", "_col_names=['remember_index','sex','age','race', 'juv_fel_count','juv_misd_count','juv_other_count','priors_count',\"c_charge_desc\",\"c_charge_degree\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rocted_col_name=\"race\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def LFR_custom(df_train,y_train,lfr=None):\n", "    from aif360.algorithms.preprocessing import LFR\n", "    from aif360.datasets import BinaryLabelDataset\n", "    \n", "    df_train=pd.concat([df_train,y_train],axis=1)\n", "    \n", "    X_col_names_f=['Gender', 'BirthYear', 'LoanPeriod', 'NumberAts']\n", "    df2_all=df_train.drop(columns=X_col_names_f).copy() #Gemmer alle kolonner, undtagen numerical og gender\n", "    df2=df_train[X_col_names_f+[\"Fall\"]].copy() #Gem kun numerical features\n", "    df2_gender=df_train[\"Gender\"].copy() #Gemmer bare gender\n", "    \n", "    \n", "    #Create the binarylabeldataset\n", "    df_BLD = BinaryLabelDataset(favorable_label='1',\n", "                                unfavorable_label='0',\n", "                                df=df2,\n", "                                label_names=['Fall'],\n", "                                protected_attribute_names=[\"Gender\"],\n", "                                unprivileged_protected_attributes=['0'])\n", "    #Define the DI remover\n", "    if lfr is None:\n", "        lfr = LFR(privileged_groups=[{\"Gender\": 1}], \n", "                                    unprivileged_groups=[{\"Gender\": 0}])\n", "        rp_df = lfr.fit_transform(df_BLD)\n", "    else:\n", "        rp_df = lfr.transform(df_BLD)\n", "        \n\n", "    #Save the columnnames\n", "    all_col_names=df_BLD.feature_names+df_BLD.label_names\n", "        \n", "        \n", "    \n", "    #Save repaired data as pandas DF\n", "    rp_df_pd = pd.DataFrame(np.hstack([rp_df.features,rp_df.labels]),columns=all_col_names) \n", "    \n", "    #Somehow gender is also transformed! So we drop it! DETTE SKAL VI NOK LIGE HOLDE \u00c3\u02dcJE MED\n", "    ###OBS!#####\n", "    rp_df_pd = rp_df_pd.drop(columns=[\"Gender\"])\n", "    #rp_df_pd = pd.concat([rp_df_pd,df2_gender],axis=1)\n\n", "    ##########\n", "    \n", "    \n", "    #Concatenate the non-numerical columns\n", "    transformed_data = pd.concat ([rp_df_pd,df2_all], axis=1)\n", "    \n", "    \n", "    transformed_data=transformed_data.drop(columns=[\"Fall\"])\n", "    \n", "    return transformed_data,lfr"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def DI_remove_custom(df_train,RP_level=1.0):\n", "    from aif360.algorithms.preprocessing import DisparateImpactRemover\n", "    from aif360.datasets import BinaryLabelDataset\n", "    X_col_names_f=['Gender', 'BirthYear', 'LoanPeriod', 'NumberAts']\n", "    df2_all=df_train.drop(columns=X_col_names_f).copy() #Gemmer alle kolonner, undtagen numerical og gender\n", "    df2=df_train[X_col_names_f].copy() #Gem kun numerical features\n", "    \n", "    df2[\"dummy\"]=1 # this is a dummy variable, since DI remover dont use y. \n", "    \n", "    #Create the binarylabeldataset\n", "    df_BLD = BinaryLabelDataset(favorable_label='1',\n", "                                unfavorable_label='0',\n", "                                df=df2,\n", "                                label_names=['dummy'],\n", "                                protected_attribute_names=[\"Gender\"],\n", "                                unprivileged_protected_attributes=['0'])\n", "    #Define the DI remover\n", "    di = DisparateImpactRemover(repair_level=RP_level)\n", "    #Save the columnnames\n", "    all_col_names=df_BLD.feature_names+df_BLD.label_names\n", "    #Reparing the data\n", "    rp_df = di.fit_transform(df_BLD)  \n", "    #Save repaired data as pandas DF\n", "    rp_df_pd = pd.DataFrame(np.hstack([rp_df.features,rp_df.labels]),columns=all_col_names) \n", "    #Concatenate the non-numerical columns\n", "    transformed_data = pd.concat ([rp_df_pd,df2_all], axis=1)\n", "    \n", "    \n", "    transformed_data_train=transformed_data.drop(columns=[\"dummy\"])\n", "    \n", "    return transformed_data_train"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_nodes=2000"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["batch_size=40\n", "epochs=200\n", "p_drop=0.5"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optim_type=\"Adam\" #SGD\n", "lr=0.001 #0.001 er godt\n", "wd=0.05       "]}, {"cell_type": "markdown", "metadata": {}, "source": [".01 er godt til AIR ny!!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from tqdm.notebook import tqdm\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "#import torchvision.datasets as datasets\n", "from torch.utils.data import DataLoader\n", "#import torchvision.transforms as transforms\n", "import matplotlib.pyplot as plt\n", "import torch.optim as optim\n", "from IPython.display import clear_output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd \n", "import seaborn as sns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "plt.style.use('seaborn')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import plot_confusion_matrix\n", "from sklearn.metrics import confusion_matrix\n", "import matplotlib.patches as mpatches\n", "from matplotlib.patches import Patch\n", "from matplotlib.lines import Line2D"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from sklearn.model_selection import train_test_split\n", "from sklearn import preprocessing"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rom google.colab import drive"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import KFold"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from datetime import datetime"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pytz\n", "import random"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "from sklearn.model_selection import StratifiedKFold"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[6]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot([0,0])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[7]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utils_Copy import *"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[8]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def loss_fn(target,predictions):\n", "    criterion = nn.BCELoss()\n", "    loss_out = criterion(predictions, target)\n", "    return loss_out"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[9]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def accuracy(true,pred):\n", "    acc = (true.float().round() == pred.float().round()).float().detach().cpu().numpy()\n", "    return float(100 * acc.sum() / len(acc))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_test():\n", "    avg_loss_ts = 0\n", "    avg_acc_ts=0\n", "    model.eval()  # train mode\n", "    for X_batch, Y_batch in data_ts:\n", "        X_batch = X_batch.to(device)\n", "        Y_batch = Y_batch.to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        # forward\n", "        Y_pred = model(X_batch.float()) \n", "        loss = loss_fn(Y_batch.float(), Y_pred.squeeze()) \n\n", "        # calculate metrics to show the user\n", "        avg_loss_ts += loss / len(data_ts)\n", "        avg_acc_ts+=accuracy(Y_batch,Y_pred.squeeze()) / len(data_ts)\n", "    #toc = time()\n", "    return avg_loss_ts, avg_acc_ts"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_all_time_low(all_time,new_val):\n", "    if all_time>new_val:\n", "        return new_val\n", "    else:\n", "        return all_time\n", "    \n", "def get_all_time_high(all_time,new_val):\n", "    if all_time<new_val:\n", "        return new_val\n", "    else:\n", "        return all_time"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[10]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Network(nn.Module):\n", "    def __init__(self):\n", "        super(Network, self).__init__()\n", "        self.fully_connected1 = nn.Sequential(\n", "            nn.Linear(n_feat,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )\n", "        self.fully_connectednew = nn.Sequential(\n", "            nn.Linear(n_nodes,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )\n", "        self.fully_connectednew1 = nn.Sequential(\n", "            nn.Linear(n_nodes,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )\n", "        self.fully_connectednew2 = nn.Sequential(\n", "            nn.Linear(n_nodes,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )\n", "        self.fully_connectednew3 = nn.Sequential(\n", "            nn.Linear(n_nodes,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        self.fully_connected2 = nn.Sequential(\n", "            nn.Linear(n_nodes,output_dim),\n", "            #nn.Softmax(dim = 1)\n", "            nn.Sigmoid()\n", "            )\n", "    def forward(self, x):\n", "      #reshaping x so it becomes flat, except for the first dimension (which is the minibatch)\n", "        #x = x.view(x.size(0),-1)\n", "        x = self.fully_connected1(x)\n", "        x = self.fully_connectednew(x)\n", "        x = self.fully_connectednew1(x)\n", "        x = self.fully_connectednew2(x)\n", "        x = self.fully_connectednew3(x)\n", "        x = self.fully_connected2(x)\n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[11]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def custom_create_indexes(df,n,seed,strat=False,y_col=None):\n", "    list_of_index=[]\n", "    \n", "    \n", "    \n", "    if strat==False:\n", "        kf=KFold(n_splits=n, random_state=seed, shuffle=True)\n", "        \n", "        \n", "        for train_index, test_index in kf.split(df):\n", "            list_of_index.append(test_index)\n", "        tr_val_ts_indexes=[\n", "        #[[train],[validate],[test]]\n", "        [[*list_of_index[0],*list_of_index[1],*list_of_index[2]],list_of_index[3],list_of_index[4]],\n", "        [[*list_of_index[4],*list_of_index[0],*list_of_index[1]],list_of_index[2],list_of_index[3]],\n", "        [[*list_of_index[3],*list_of_index[4],*list_of_index[0]],list_of_index[1],list_of_index[2]],\n", "        [[*list_of_index[2],*list_of_index[3],*list_of_index[4]],list_of_index[0],list_of_index[1]],\n", "        [[*list_of_index[1],*list_of_index[2],*list_of_index[3]],list_of_index[4],list_of_index[0]],\n", "        ]\n", "    \n", "    \n", "    \n", "    \n", "    else:\n", "        kf = StratifiedKFold(n_splits=n, random_state=seed, shuffle=True)\n", "    \n", "    \n", "        for train_index, test_index in kf.split(df,df[y_col]):\n", "            list_of_index.append(test_index)\n", "        tr_val_ts_indexes=[\n", "        #[[train],[validate],[test]]\n", "        [[*list_of_index[0],*list_of_index[1],*list_of_index[2]],list_of_index[3],list_of_index[4]],\n", "        [[*list_of_index[4],*list_of_index[0],*list_of_index[1]],list_of_index[2],list_of_index[3]],\n", "        [[*list_of_index[3],*list_of_index[4],*list_of_index[0]],list_of_index[1],list_of_index[2]],\n", "        [[*list_of_index[2],*list_of_index[3],*list_of_index[4]],list_of_index[0],list_of_index[1]],\n", "        [[*list_of_index[1],*list_of_index[2],*list_of_index[3]],list_of_index[4],list_of_index[0]],\n", "        ]\n", "    \n", "    return tr_val_ts_indexes"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[12]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["modelcounter=0\n", "for custom_seed in range(1,11):\n", "    \n", "    torch.manual_seed(custom_seed)\n", "    random.seed(custom_seed)\n", "    np.random.seed(custom_seed)\n", "    \n", "    df2 = pd.read_csv(full_file_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["   \n", "    X=df2[X_col_names]\n", "    if dropping_D==True:\n", "        y=df2[[y_col_name,procted_col_name]]\n", "    else:\n", "        y=df2[[y_col_name]]\n\n", "    #https://stackoverflow.com/questions/11587782/creating-dummy-variables-in-pandas-for-python\n", "    if AIR==False:\n", "        just_dummies=pd.get_dummies(X[['sex',\"race\",\"c_charge_desc\",\"c_charge_degree\"]])\n", "        X = pd.concat([X, just_dummies], axis=1) \n", "        X=X.drop(['sex',\"race\",\"c_charge_desc\",\"c_charge_degree\"] ,axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    \n", "    tr_val_ts_indexes= custom_create_indexes(X,5,custom_seed)\n", "    #tr_val_ts_indexes= custom_create_indexes(df2,5,custom_seed,True,y_col_name) #stratify\n\n", "    #i=0\n", "    for mini_loop in range(len(tr_val_ts_indexes)):\n", "        print(\"Running overall number \"+str(modelcounter))\n", "         \n", "        \n", "        X_train_pd, y_train_pd = X.iloc[tr_val_ts_indexes[mini_loop][0]], y.iloc[tr_val_ts_indexes[mini_loop][0]]\n", "        X_val_pd, y_val_pd = X.iloc[tr_val_ts_indexes[mini_loop][1]], y.iloc[tr_val_ts_indexes[mini_loop][1]]\n", "        X_test_pd, y_test_pd = X.iloc[tr_val_ts_indexes[mini_loop][2]], y.iloc[tr_val_ts_indexes[mini_loop][2]]\n", "        \n", "        \n", "        seedName=\"model\"+str(modelcounter)\n", "        PATH=PATH_orig+seedName+\"/\"\n", "        print(PATH)\n\n", "        #Make dir to files\n", "        if not os.path.exists(PATH):\n", "            os.makedirs(PATH)\n", "            print(\"Created new path!: \",PATH)\n", "        \n", "        \n", "        if gender_swap==True:\n", "            X_train_pd_copy=X_train_pd.copy()\n", "            y_train_pd_copy=y_train_pd.copy()\n", "            \n", "            X_train_pd_copy[\"Gender\"]=(X_train_pd_copy[\"Gender\"]-1)*(-1)\n", "            \n", "            X_train_pd=pd.concat([X_train_pd,X_train_pd_copy])\n", "            \n", "            y_train_pd=pd.concat([y_train_pd,y_train_pd_copy])\n", "            \n", "            \n", "            \n", "            \n", "        if DI_remove==True:\n", "            X_train_pd=DI_remove_custom(X_train_pd.reset_index(drop=True))\n", "            X_val_pd=DI_remove_custom(X_val_pd.reset_index(drop=True))\n", "            X_test_pd=DI_remove_custom(X_test_pd.reset_index(drop=True))\n", "            \n", "            y_train_pd=y_train_pd.reset_index(drop=True)\n", "            \n", "            y_val_pd=y_val_pd.reset_index(drop=True)\n", "            \n", "            y_test_pd=y_test_pd.reset_index(drop=True)\n", "            \n", "            \n", "        if LFR_mitigation==True:\n", "            \n", "            \n", "            X_train_pd,lfr=LFR_custom(X_train_pd.reset_index(drop=True),\n", "                                  y_train_pd.reset_index(drop=True).drop(columns=[\"Gender\"]),\n", "                                 lfr=None\n", "                                 )\n", "            X_val_pd,lfr=LFR_custom(X_val_pd.reset_index(drop=True),\n", "                                  y_val_pd.reset_index(drop=True).drop(columns=[\"Gender\"]),\n", "                                 lfr=lfr\n", "                                 )\n", "            X_test_pd,lfr=LFR_custom(X_test_pd.reset_index(drop=True),\n", "                                  y_test_pd.reset_index(drop=True).drop(columns=[\"Gender\"]),\n", "                                 lfr=lfr\n", "                                 )\n", "            \n", "            y_train_pd=y_train_pd.reset_index(drop=True)\n", "            \n", "            y_val_pd=y_val_pd.reset_index(drop=True)\n", "            \n", "            y_test_pd=y_test_pd.reset_index(drop=True)\n", "            \n", "            \n", "            \n", "        X_train, y_train = X_train_pd, y_train_pd\n", "        X_val, y_val = X_val_pd, y_val_pd\n", "        X_test, y_test = X_test_pd, y_test_pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        #Save as numpy array for the DATALOADER (PyTorch)\n", "        \n", "        if LFR_mitigation==True:\n", "            temp_col_name_LFR=[name for name in X_col_names if name not in [\"Gender\"]]\n", "            X_train=np.array(X_train[temp_col_name_LFR])\n", "            y_train=np.array(y_train[y_col_name])\n", "            X_val=np.array(X_val[temp_col_name_LFR])\n", "            y_val=np.array(y_val[y_col_name])\n", "            X_test=np.array(X_test[temp_col_name_LFR])\n", "            y_test=np.array(y_test[y_col_name])\n", "        \n", "        \n", "        else:\n", "            \n", "            X_train=np.array(X_train[X_col_names])\n", "            y_train=np.array(y_train[y_col_name])\n", "            X_val=np.array(X_val[X_col_names])\n", "            y_val=np.array(y_val[y_col_name])\n", "            X_test=np.array(X_test[X_col_names])\n", "            y_test=np.array(y_test[y_col_name])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["       # print(\"X_train shape: {}\".format(X_train.shape))\n", "       # print(\"y_train shape: {}\".format(y_train.shape))\n\n", "        #print(\"X_val shape: {}\".format(X_val.shape))\n", "        #print(\"y_val shape: {}\".format(y_val.shape))\n\n", "        #print(\"X_test shape: {}\".format(X_test.shape))\n", "        #print(\"y_test shape: {}\".format(y_test.shape))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        #n_feat=X_train.shape[1]\n", "        \n", "        if LFR_mitigation==True:\n", "            n_feat=len(X_col_names)-1#minus gender\n", "        \n", "        else:\n", "            n_feat=len(X_col_names)\n", "        \n", "        \n", "        output_dim=1 #binary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        data_tr = DataLoader(list(zip(X_train, y_train)), batch_size=batch_size, shuffle=False)\n", "        data_val = DataLoader(list(zip(X_val, y_val)), batch_size=batch_size, shuffle=False)\n", "        data_ts = DataLoader(list(zip(X_test, y_test)), batch_size=batch_size, shuffle=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "        #device=\"cpu\"\n", "        print(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        model = Network().to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        opt=optim.Adam(model.parameters(),lr=lr, weight_decay = wd)\n", "        \n", "        epochnumber = []\n", "        all_train_losses = []\n", "        all_val_losses = []\n", "        all_ts_losses = []\n", "        all_train_acc=[]\n", "        all_val_acc=[]\n", "        all_ts_acc=[]\n", "        all_time_low_train_loss=1000\n", "        all_time_low_val_loss=1000\n", "        all_time_high_train_acc=0\n", "        all_time_high_val_acc=0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        for epoch in range(epochs):\n", "            if (epoch)%20==0:\n", "                print('* Epoch %d/%d' % (epoch+1, epochs))\n", "            epochnumber.append(epoch)\n", "            avg_loss_train = 0\n", "            avg_acc=0\n", "            model.train()  # train mode\n", "            for X_batch, Y_batch in data_tr:\n", "                X_batch = X_batch.to(device)\n", "                Y_batch = Y_batch.to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                # set parameter gradients to zero\n", "                opt.zero_grad()\n", "                # forward\n", "                Y_pred = model(X_batch.float()) #oprdindeligt havde vi 3 lag (RGB), nu har vi kun 1 (greyscale) -> \n", "                loss = loss_fn(Y_batch.float(), Y_pred.squeeze())  # forward-pass\n", "                loss.backward()  # backward-pass\n", "                opt.step()  # update weights\n", "                # calculate metrics to show the user\n", "                avg_loss_train += loss / len(data_tr)\n", "                avg_acc+=accuracy(Y_batch,Y_pred.squeeze()) / len(data_tr)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            all_time_low_train_loss=get_all_time_low(all_time_low_train_loss,avg_loss_train)\n", "            all_time_low_train_acc=get_all_time_high(all_time_high_train_acc,avg_acc)\n", "              #print(' - train loss: %f' % avg_loss_train)\n", "              #print(' - train acc: {} %'.format(round(avg_acc,2)))\n", "            all_train_losses.append(avg_loss_train)\n", "            all_train_acc.append(avg_acc)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            with torch.no_grad():\n", "                avg_loss_val = 0\n", "                avg_acc_val=0\n", "                model.eval()  # eval mode\n", "                for X_batch, Y_batch in data_val:\n", "                    X_batch = X_batch.to(device)\n", "                    Y_batch = Y_batch.to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                    # forward\n", "                    Y_pred = model(X_batch.float()) \n", "                    loss = loss_fn(Y_batch.float(), Y_pred.squeeze())  # forward-pass\n", "                    # calculate metrics to show the user\n", "                    avg_loss_val += loss / len(data_val)\n", "                    avg_acc_val+=accuracy(Y_batch,Y_pred.squeeze()) / len(data_val)\n", "                #toc = time()\n", "                all_time_low_val_loss=get_all_time_low(all_time_low_val_loss,avg_loss_val)\n", "                all_time_low_val_acc=get_all_time_high(all_time_high_val_acc,avg_acc_val)\n", "                #print(' - val loss: %f' % avg_loss_val)\n", "                #print(' - val acc: {} %'.format(round(avg_acc_val,2)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                ########Save model####\n", "            if  epoch == 0 or avg_loss_val <= min(all_val_losses) :\n", "                torch.save(model.state_dict(), PATH+'_FFNN_model_local.pth')\n", "                print('####Saved model####')\n", "            all_val_losses.append(avg_loss_val)\n", "            all_val_acc.append(avg_acc_val)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["          ###PLOT########\n", "        if epoch==epochs-1:\n", "            #Save the last epoch\n", "            torch.save(model.state_dict(), PATH+'_FFNN_model_global.pth')\n\n", "            #take the best model (with lowest validation loss)\n", "            model.load_state_dict(torch.load(PATH+'_FFNN_model_local.pth'))\n", "            model.eval()\n", "            all_ts_losses=[get_test()[0]] * (epoch+1)\n", "            all_ts_acc=[get_test()[1]] * (epoch+1)\n", "            plt.figure(1)\n", "            plt.plot(epochnumber, all_train_losses, 'r', epochnumber, all_val_losses, 'b',epochnumber, all_ts_losses, '--')\n", "            plt.xlabel('Epochs'), plt.ylabel('Loss')\n", "            plt.legend(['Train Loss', 'Val Loss','Test loss'])\n", "            plt.savefig(PATH+'_loss.png')\n", "            plt.show()\n", "            plt.figure(2)\n", "            plt.plot(epochnumber, all_train_acc, 'black', epochnumber, all_val_acc, 'grey',epochnumber, all_ts_acc, '--')\n", "            plt.xlabel('Epochs'), plt.ylabel('Accuracy')\n", "            plt.legend(['Train acc', 'Val acc','Test acc'])\n", "            plt.savefig(PATH+'_acc.png')\n", "            plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            metrics=pd.DataFrame({\"all_time_low_train_loss\":[all_time_low_train_loss.item()],\n", "                                  \"all_time_low_train_acc\":[all_time_low_train_acc],\n", "                              \"all_time_low_val_loss\":[all_time_low_val_loss.item()],\n", "                                  \"all_time_val_train_acc\":[all_time_low_val_acc],\n", "                              \"test_acc\":[all_ts_acc[0]],\n", "                              \"test_loss\":[all_ts_losses[0].item()]\n", "                                                })\n", "            metrics.to_csv( PATH+'_metrics.csv')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            for local_best in [0,1]:\n", "                #local_best=0\n", "                model1 = Network().to(device)\n", "                if local_best==1:\n", "                    model1.load_state_dict(torch.load(PATH+'_FFNN_model_local.pth'))\n", "                else:\n", "                    model1.load_state_dict(torch.load(PATH+'_FFNN_model_global.pth'))\n", "                model1.eval()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                df_evaluate = X_test_pd.copy()\n", "                df_evaluate[y_col_name]=y_test_pd[y_col_name]\n", "                if dropping_D==True:\n", "                    df_evaluate[procted_col_name]=y_test_pd[procted_col_name]\n", "                else:\n", "                    df_evaluate[procted_col_name]=X_test_pd[procted_col_name]\n", "                if AIR==False:\n", "                    cols= [col for col in list(df_evaluate.columns) if col not in [y_col_name,\"sex\",\"age_cat\",\"race\",\"c_charge_desc\",\"c_charge_degree\"]]\n", "                else:\n", "                    if dropping_D==True:\n", "                        cols= [col for col in list(df_evaluate.columns) if col not in [y_col_name,procted_col_name]]\n", "                    elif gender_swap==True:\n", "                        cols= [col for col in list(df_evaluate.columns) if col not in [y_col_name,\"Original\"]]\n", "                    else:\n", "                        cols= [col for col in list(df_evaluate.columns) if col not in [y_col_name]]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                X_numpy=np.array(df_evaluate[cols])\n", "                X_torch=torch.tensor(X_numpy)\n", "                y_pred = model1(X_torch.float().to(device))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                list_of_output=[round(a.item(),0) for a in y_pred.detach().cpu()]\n", "                list_of_output_prob=[a.item() for a in y_pred.detach().cpu()]\n", "                df_evaluate[\"output\"]=list_of_output\n", "                df_evaluate[\"output_prob\"]=list_of_output_prob\n", "                df_evaluate[\"Model\"]=seedName"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                ##SAVING THE TEST DATA\n", "                if local_best==1:\n", "                    df_evaluate.to_csv(PATH+\"test_data_localmodel.csv\")\n", "                else:\n", "                    df_evaluate.to_csv(PATH+\"test_data_globalmodel.csv\")\n", "            \n", "        modelcounter=modelcounter+1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Save all test data (and output)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[13]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for file_name in [\"localmodel\",\"globalmodel\"]:\n", "    first_time=True\n", "    \n", "    for j in range(modelcounter):\n", "        \n", "        if first_time==True:\n", "            test_data_all = pd.read_csv(PATH_orig+\"model\"+str(j)+\"/test_data_\"+file_name+\".csv\")\n", "            first_time=False\n", "        else:\n", "            test_subset=pd.read_csv(PATH_orig+\"model\"+str(j)+\"/test_data_\"+file_name+\".csv\")\n", "            test_data_all=pd.concat([test_data_all,test_subset],sort=False,axis=0)\n", "       \n", "       \n", "    test_data_all.to_csv(PATH_orig+\"all_test_data_\"+file_name+\".csv\")\n", "    print(f\"the shape of {file_name} is {test_data_all.shape}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": [" # GLOBAL ALL"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[14]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["olumn_names = [\"Group\", \"ML\", \"Measure\",\"Value\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["f_out = pd.DataFrame(columns = column_names)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["or i in range(50):"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  \n", "#    PATH_loop=PATH_orig+\"model\"+str(i)+\"/_all_stats_global.csv\"\n", "  \n", "#    data=pd.read_csv(PATH_loop)\n", "#    for group in [\"all\"]:\n", "#        for measure in ['FPR', 'FNR', 'ACC', 'F1', 'FDR', 'LRminus','LRplus', 'NPV', 'PPV', 'TNR', 'TPR','TP','TN','FN','FP']:\n", "#            value=float(data[data[procted_col_name]==group][measure])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["           df_out=df_out.append({'Group': group,\"ML\":\"FFNN\"+str(i),\"Measure\":measure,\"Value\":value}, ignore_index=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["f_out.to_csv(PATH_orig+\"/FFNN_metrics_crossvalidated_global_all.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[15]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lobal_all_bar=sns.barplot(data=df_out[df_out[\"Measure\"].isin([\"FPR\",\"FNR\",\"TPR\",\"TNR\"])],x=\"Group\", y=\"Value\", ci=95,hue=\"Measure\")<br>\n", "lobal_all_bar.set_title('Global all')<br>\n", "lobal_all_bar.get_figure().savefig(PATH_orig+\"/barplot_global_all.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# LOCAL ALL"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[16]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["olumn_names = [\"Group\", \"ML\", \"Measure\",\"Value\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["f_out = pd.DataFrame(columns = column_names)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["or i in range(50):<br>\n", "<br>\n", "   PATH_loop=PATH_orig+\"model\"+str(i)+\"/_all_stats_local.csv\"<br>\n", " <br>\n", "   data=pd.read_csv(PATH_loop)<br>\n", "   for group in [\"all\"]:<br>\n", "       for measure in ['FPR', 'FNR', 'ACC', 'F1', 'FDR', 'LRminus','LRplus', 'NPV', 'PPV', 'TNR', 'TPR','TP','TN','FN','FP',\"y_hat_mean\",\"y_target_mean\"]:<br>\n", "           value=float(data[data[procted_col_name]==group][measure])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["           df_out=df_out.append({'Group': group,\"ML\":\"FFNN\"+str(i),\"Measure\":measure,\"Value\":value}, ignore_index=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["f_out.to_csv(PATH_orig+\"FFNN_metrics_crossvalidated_local_all.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[17]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ocal_all_bar=sns.barplot(data=df_out[df_out[\"Measure\"].isin([\"FPR\",\"FNR\",\"TPR\",\"TNR\"])],x=\"Group\", y=\"Value\", ci=95,hue=\"Measure\")<br>\n", "ocal_all_bar.set_title('Global all')<br>\n", "ocal_all_bar.get_figure().savefig(PATH_orig+\"/barplot_local_all.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Global protected"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[18]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["olumn_names = [\"Group\", \"ML\", \"Measure\",\"Value\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["f_out = pd.DataFrame(columns = column_names)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["or i in range(50):"]}, {"cell_type": "markdown", "metadata": {}, "source": ["   PATH_loop=PATH_orig+\"model\"+str(i)+\"/_\"+procted_col_name+\"_stats_global.csv\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  \n", "#    data=pd.read_csv(PATH_loop)\n", "#    for group in list(data[procted_col_name].unique()):\n", "#        for measure in ['FPR', 'FNR', 'ACC', 'F1', 'FDR', 'LRminus','LRplus', 'NPV', 'PPV', 'TNR', 'TPR','TP','TN','FN','FP',\"y_hat_mean\",\"y_target_mean\"]:\n", "#            value=float(data[data[procted_col_name]==group][measure])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" #           df_out=df_out.append({'Group': group,\"ML\":\"FFNN\"+str(i),\"Measure\":measure,\"Value\":value}, ignore_index=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["f_out.to_csv(PATH_orig+\"FFNN_metrics_crossvalidated_global_\"+procted_col_name+\".csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[19]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lobal_proc_bar=sns.barplot(data=df_out[df_out[\"Measure\"].isin([\"FPR\",\"FNR\",\"TPR\",\"TNR\"])],x=\"Group\", y=\"Value\", ci=95,hue=\"Measure\")<br>\n", "lobal_proc_bar.set_title('Global proctected: '+procted_col_name)<br>\n", "lobal_proc_bar.get_figure().savefig(PATH_orig+\"/barplot_global_proc.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Local protected"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[20]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["olumn_names = [\"Group\", \"ML\", \"Measure\",\"Value\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["f_out = pd.DataFrame(columns = column_names)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["or i in range(50):<br>\n", "   PATH_loop=PATH_orig+\"model\"+str(i)+\"/_\"+procted_col_name+\"_stats_local.csv\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  \n", "#    data=pd.read_csv(PATH_loop)\n", "#    for group in list(data[procted_col_name].unique()):\n", "#        for measure in ['FPR', 'FNR', 'ACC', 'F1', 'FDR', 'LRminus','LRplus', 'NPV', 'PPV', 'TNR', 'TPR','TP','TN','FN','FP',\"y_hat_mean\",\"y_target_mean\"]:\n", "#            value=float(data[data[procted_col_name]==group][measure])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["           df_out=df_out.append({'Group': group,\"ML\":\"FFNN\"+str(i),\"Measure\":measure,\"Value\":value}, ignore_index=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["f_out.to_csv(PATH_orig+\"FFNN_metrics_crossvalidated_local_\"+procted_col_name+\".csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[21]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ocal_proc_bar=sns.barplot(data=df_out[df_out[\"Measure\"].isin([\"FPR\",\"FNR\",\"TPR\",\"TNR\"])],x=\"Group\", y=\"Value\", ci=95,hue=\"Measure\")<br>\n", "ocal_proc_bar.set_title('Local protected: '+procted_col_name)<br>\n", "ocal_proc_bar.get_figure().savefig(PATH_orig+\"/barplot_local_proc.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[22]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "for file_name in [\"localmodel\",\"globalmodel\"]:<br>\n", "    <br>\n", "    for j in range(modelcounter):<br>\n", "    <br>\n", "        test_data_0 = pd.read_csv(PATH_orig+\"model0/test_data_\"+file_name+\".csv\")<br>\n", "        test_data_1 = pd.read_csv(PATH_orig+\"model1/test_data_\"+file_name+\".csv\")<br>\n", "        test_data_2 = pd.read_csv(PATH_orig+\"model2/test_data_\"+file_name+\".csv\")<br>\n", "        test_data_3 = pd.read_csv(PATH_orig+\"model3/test_data_\"+file_name+\".csv\")<br>\n", "        test_data_4 = pd.read_csv(PATH_orig+\"model4/test_data_\"+file_name+\".csv\")<br>\n", "        test_data_5 = pd.read_csv(PATH_orig+\"model5/test_data_\"+file_name+\".csv\")<br>\n", "        test_data_6 = pd.read_csv(PATH_orig+\"model6/test_data_\"+file_name+\".csv\")<br>\n", "        test_data_7 = pd.read_csv(PATH_orig+\"model7/test_data_\"+file_name+\".csv\")<br>\n", "        test_data_8 = pd.read_csv(PATH_orig+\"model8/test_data_\"+file_name+\".csv\")<br>\n", "        test_data_9 = pd.read_csv(PATH_orig+\"model9/test_data_\"+file_name+\".csv\")<br>\n", "        df2=    pd.concat([test_data_0,<br>\n", "                            test_data_1,<br>\n", "                            test_data_2,<br>\n", "                            test_data_3,<br>\n", "                            test_data_4,<br>\n", "                            test_data_5,<br>\n", "                            test_data_6,<br>\n", "                            test_data_7,<br>\n", "                            test_data_8,<br>\n", "                            test_data_9<br>\n", "                           ],sort=False,axis=0)<br>\n", "    df2.to_csv(PATH_orig+\"all_test_data_\"+file_name+\".csv\")<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}