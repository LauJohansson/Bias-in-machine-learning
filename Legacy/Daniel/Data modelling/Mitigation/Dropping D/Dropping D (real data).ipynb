{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[69]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "from sklearn import preprocessing\n", "import math "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[70]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data = pd.read_csv('/restricted/s161749/G2020-57-Aalborg-bias/Data_air/Fall_count_clusterOHE_std.csv')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[71]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data['Gender'].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Gender bias"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[72]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[73]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data['Fall'].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[74]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[75]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = fall_data.drop(columns=['Unnamed: 0','Fall']) # using all covariates in the dataset. ,'Ats_0'\n", "#X1 = pd.DataFrame(preprocessing.scale(X1),columns=X1.columns)\n", "#X2 = pd.DataFrame(fall_data['Gender'])\n", "#X = pd.concat([X1],axis=1)\n", "y = fall_data[['Gender','Fall']]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[76]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X.columns"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[77]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X.max().sort_values(ascending=False).head(10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[103]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import svm, datasets\n", "from sklearn.metrics import plot_confusion_matrix\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.model_selection import KFold"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Creating empty lists for:<br>\n", "TP/TN/FP/FN"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TP_list_W=[]\n", "TN_list_W=[]\n", "FP_list_W=[]\n", "FN_list_W=[]\n", "F1_list_W=[]\n", "ACC_list_W=[]\n", "TPR_list_W=[]\n", "TNR_list_W=[]\n", "FPR_list_W=[]\n", "FNR_list_W=[]\n", "yhat_list_W=[]\n", "yhat_prob_list_W=[]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TP_list_M=[]\n", "TN_list_M=[]\n", "FP_list_M=[]\n", "FN_list_M=[]\n", "F1_list_M=[]\n", "ACC_list_M=[]\n", "TPR_list_M=[]\n", "TNR_list_M=[]\n", "FPR_list_M=[]\n", "FNR_list_M=[]\n", "yhat_list_M=[]\n", "yhat_prob_list_M=[]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ACC_list_total=[]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_names = ['No fall','Fall']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(1,11):\n", "    \n", "    kf=KFold(n_splits=5, random_state=i, shuffle=True)\n", "    \n", "    for train_index, test_index in kf.split(X):\n", "        \n", "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n", "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n", "    \n", "    #### Flip fra den ene til den anden for at skifte mellem SVM, LR og RF ###\n", "    \n", "        \n", "        #classifier = svm.SVC(kernel='rbf', C=1, random_state=0,class_weight='balanced',probability=True).fit(X_train.drop(columns=['Gender']) , y_train['Fall'])\n", "        #classifier = LogisticRegression(max_iter=1000,class_weight='balanced').fit(X_train.drop(columns=['Gender']), y_train['Fall'])\n", "        classifier = RandomForestClassifier(random_state=1).fit(X_train.drop(columns=['Gender']), y_train['Fall'])\n", "    \n", "   # class weight balanced?  \n", "   # \n", "        np.set_printoptions(precision=2)\n", "    # Plot non-normalized confusion matrix\n", "        titles_options = [(\"Confusion matrix, without normalization\", None)]\n", "    \n", "    \n", "        \n", "     ############ FOR WOMEN ################   \n", "        \n", "        for title, normalize in titles_options:\n", "            disp = plot_confusion_matrix(classifier, X_test[X_test['Gender']==0].drop(columns=['Gender']),\n", "                                         y_test[y_test['Gender']==0]['Fall'], \n", "                                     display_labels=class_names,\n", "                                     cmap=plt.cm.Blues, normalize=normalize)\n", "    \n", "        # getting TP/TN/FP/FN\n", "        TP=disp.confusion_matrix[1][1]\n", "        TN=disp.confusion_matrix[0][0]\n", "        FP=disp.confusion_matrix[0][1]\n", "        FN=disp.confusion_matrix[1][0]\n", "        F1=2*TP/(2*TP+FP+FN)\n", "        ACC=classifier.score(X_test[X_test['Gender']==0].drop(columns=['Gender']), y_test[y_test['Gender']==0]['Fall']) # mark gender\n", "        yhat=np.mean(classifier.predict(X_test[X_test['Gender']==0].drop(columns=['Gender'])))\n", "        yhat_prob=pd.DataFrame(classifier.predict_proba(X_test[X_test['Gender']==0].drop(columns=['Gender'])))[1].mean()\n", "        \n", "        # rates\n", "        FNR = FN/(FN+TP)\n", "        FPR = FP/(FP+TN)\n", "        TNR = TN/(TN+FP)\n", "        TPR = TP/(TP+FN)\n", "        \n", "        # appending to lists\n", "        TP_list_W.append(TP)\n", "        TN_list_W.append(TN)\n", "        FP_list_W.append(FP)\n", "        FN_list_W.append(FN)\n", "        F1_list_W.append(F1)\n", "        ACC_list_W.append(ACC)\n", "        TPR_list_W.append(TPR)\n", "        TNR_list_W.append(TNR)\n", "        FPR_list_W.append(FPR)\n", "        FNR_list_W.append(FNR)\n", "        yhat_list_W.append(yhat)\n", "        yhat_prob_list_W.append(yhat_prob)\n", "        \n", "        \n", "    ############ FOR MEN ################    \n", "        \n", "        \n", "        for title, normalize in titles_options:\n", "            disp = plot_confusion_matrix(classifier, X_test[X_test['Gender']==1].drop(columns=['Gender']),\n", "                                         y_test[y_test['Gender']==1]['Fall'], \n", "                                     display_labels=class_names,\n", "                                     cmap=plt.cm.Blues, normalize=normalize)\n", "    \n", "        # getting TP/TN/FP/FN\n", "        TP=disp.confusion_matrix[1][1]\n", "        TN=disp.confusion_matrix[0][0]\n", "        FP=disp.confusion_matrix[0][1]\n", "        FN=disp.confusion_matrix[1][0]\n", "        F1=2*TP/(2*TP+FP+FN)\n", "        ACC=classifier.score(X_test[X_test['Gender']==1].drop(columns=['Gender']), y_test[y_test['Gender']==1]['Fall']) # mark gender\n", "        yhat=np.mean(classifier.predict(X_test[X_test['Gender']==1].drop(columns=['Gender'])))\n", "        yhat_prob=pd.DataFrame(classifier.predict_proba(X_test[X_test['Gender']==1].drop(columns=['Gender'])))[1].mean()\n", "        \n", "        # rates\n", "        FNR = FN/(FN+TP)\n", "        FPR = FP/(FP+TN)\n", "        TNR = TN/(TN+FP)\n", "        TPR = TP/(TP+FN)\n", "        \n", "        # appending to lists\n", "        TP_list_M.append(TP)\n", "        TN_list_M.append(TN)\n", "        FP_list_M.append(FP)\n", "        FN_list_M.append(FN)\n", "        F1_list_M.append(F1)\n", "        ACC_list_M.append(ACC)\n", "        TPR_list_M.append(TPR)\n", "        TNR_list_M.append(TNR)\n", "        FPR_list_M.append(FPR)\n", "        FNR_list_M.append(FNR)\n", "        yhat_list_M.append(yhat)\n", "        yhat_prob_list_M.append(yhat_prob)\n", "        \n", "        \n", "                        \n", "    ############ FOR All ################   \n", "        ACC=classifier.score(X_test.drop(columns=['Gender']), y_test['Fall']) # mark gender\n", "        ACC_list_total.append(ACC)\n", "        "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[104]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["metricW_df=np.round(pd.DataFrame(TPR_list_W,columns=['TPR']),4)\n", "metricW_df['FPR']=np.round(pd.DataFrame(FPR_list_W),4)\n", "metricW_df['TNR']=np.round(pd.DataFrame(TNR_list_W),4)\n", "metricW_df['FNR']=np.round(pd.DataFrame(FNR_list_W),4)\n", "metricW_df['ACC']=np.round(pd.DataFrame(ACC_list_W),4)\n", "metricW_df['Mean_y_hat']=np.round(pd.DataFrame(yhat_list_W),4)\n", "metricW_df['Mean_y_hat_prob']=np.round(pd.DataFrame(yhat_prob_list_W),4)\n", "metricW_df['Gender']=0\n", "metricW_df['Model']='RF' #change to correct model\n", "colsW = list(metricW_df.columns.values)\n", "metricW_df = metricW_df[['Gender','TPR', 'FPR', 'TNR', 'FNR', 'ACC', 'Mean_y_hat', 'Mean_y_hat_prob', 'Model']]\n", "metricW_df.mean()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[105]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["metricM_df=np.round(pd.DataFrame(TPR_list_M,columns=['TPR']),4)\n", "metricM_df['FPR']=np.round(pd.DataFrame(FPR_list_M),4)\n", "metricM_df['TNR']=np.round(pd.DataFrame(TNR_list_M),4)\n", "metricM_df['FNR']=np.round(pd.DataFrame(FNR_list_M),4)\n", "metricM_df['ACC']=np.round(pd.DataFrame(ACC_list_M),4)\n", "metricM_df['Mean_y_hat']=np.round(pd.DataFrame(yhat_list_M),4)\n", "metricM_df['Mean_y_hat_prob']=np.round(pd.DataFrame(yhat_prob_list_M),4)\n", "metricM_df['Gender']=1\n", "metricM_df['Model']='RF' #change to correct model\n", "colsM = list(metricM_df.columns.values)\n", "metricM_df = metricM_df[['Gender','TPR', 'FPR', 'TNR', 'FNR', 'ACC', 'Mean_y_hat', 'Mean_y_hat_prob', 'Model']]\n", "metricM_df.mean()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[106]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["metric_df = pd.concat([metricM_df,metricW_df],axis=0)\n", "metric_df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[107]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["etric_df.to_csv('/restricted/s161749/G2020-57-Aalborg-bias/Plot_metrics/Dropping D/RF_gender.csv')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Accuracy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[108]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ACC_df=np.round(pd.DataFrame(ACC_list_total,columns=['ACC']),4)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[109]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["CC_df.to_csv('/restricted/s161749/G2020-57-Aalborg-bias/Plot_metrics/Dropping D/RF_all.csv')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## prints for latex tables"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[123]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["etrics for women"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TPRW_mean=np.round((metricW_df['TPR']*100).mean(),1)\n", "TPRW_low=np.round((metricW_df['TPR']*100).mean()-((1.96*(metricW_df['TPR']*100).std()/math.sqrt(len(metricW_df)))),1)\n", "TPRW_high=np.round((metricW_df['TPR']*100).mean()+((1.96*(metricW_df['TPR']*100).std()/math.sqrt(len(metricW_df)))),1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["FPRW_mean=np.round((metricW_df['FPR']*100).mean(),1)\n", "FPRW_low=np.round((metricW_df['FPR']*100).mean()-((1.96*(metricW_df['FPR']*100).std()/math.sqrt(len(metricW_df)))),1)\n", "FPRW_high=np.round((metricW_df['FPR']*100).mean()+((1.96*(metricW_df['FPR']*100).std()/math.sqrt(len(metricW_df)))),1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TNRW_mean=np.round((metricW_df['TNR']*100).mean(),1)\n", "TNRW_low=np.round((metricW_df['TNR']*100).mean()-((1.96*(metricW_df['TNR']*100).std()/math.sqrt(len(metricW_df)))),1)\n", "TNRW_high=np.round(metricW_df['TNR'].mean()+((1.96*metricW_df['TNR'].std()/math.sqrt(len(metricW_df)))),1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["FNRW_mean=np.round((metricW_df['FNR']*100).mean(),1)\n", "FNRW_low=np.round((metricW_df['FNR']*100).mean()-((1.96*(metricW_df['FNR']*100).std()/math.sqrt(len(metricW_df)))),1)\n", "FNRW_high=np.round((metricW_df['FNR']*100).mean()+((1.96*(metricW_df['FNR']*100).std()/math.sqrt(len(metricW_df)))),1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[124]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["etrics for men"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TPRM_mean=np.round((metricM_df['TPR']*100).mean(),1)\n", "TPRM_low=np.round((metricM_df['TPR']*100).mean()-((1.96*(metricM_df['TPR']*100).std()/math.sqrt(len(metricM_df)))),1)\n", "TPRM_high=np.round((metricM_df['TPR']*100).mean()+((1.96*(metricM_df['TPR']*100).std()/math.sqrt(len(metricM_df)))),1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["FPRM_mean=np.round((metricM_df['FPR']*100).mean(),1)\n", "FPRM_low=np.round((metricM_df['FPR']*100).mean()-((1.96*(metricM_df['FPR']*100).std()/math.sqrt(len(metricM_df)))),1)\n", "FPRM_high=np.round((metricM_df['FPR']*100).mean()+((1.96*(metricM_df['FPR']*100).std()/math.sqrt(len(metricM_df)))),1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TNRM_mean=np.round((metricM_df['TNR']*100).mean(),2)\n", "TNRM_low=np.round((metricM_df['TNR']*100).mean()-((1.96*(metricM_df['TNR']*100).std()/math.sqrt(len(metricM_df)))),1)\n", "TNRM_high=np.round((metricM_df['TNR']*100).mean()+((1.96*(metricM_df['TNR']*100).std()/math.sqrt(len(metricM_df)))),1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["FNRM_mean=np.round((metricM_df['FNR']*100).mean(),1)\n", "FNRM_low=np.round((metricM_df['FNR']*100).mean()-((1.96*(metricM_df['FNR']*100).std()/math.sqrt(len(metricM_df)))),1)\n", "FNRM_high=np.round((metricM_df['FNR']*100).mean()+((1.96*(metricM_df['FNR']*100).std()/math.sqrt(len(metricM_df)))),1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[125]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"women: \\\\textbf{\",TPRW_mean,\"} & \\\\textbf{\",FPRW_mean,\"} & \\\\textbf{\",TNRW_mean,\"} & \\\\textbf{\",FNRW_mean,\"} \\\\\\ \")\n", "print(f\"& ({TPRW_low}-{TPRW_high}) & ({FPRW_low}-{FPRW_high}) & ({TNRW_low}-{TNRW_high}) & ({FNRW_low}-{FNRW_high})\\\\\\ \")\n", "print(\"men: \\\\textbf{\",TPRM_mean,\"} & \\\\textbf{\",FPRM_mean,\"} & \\\\textbf{\",TNRM_mean,\"} & \\\\textbf{\",FNRM_mean,\"} \\\\\\ \")\n", "print(f\"& ({TPRM_low}-{TPRM_high}) & ({FPRM_low}-{FPRM_high}) & ({TNRM_low}-{TNRM_high}) & ({FNRM_low}-{FNRM_high}) \\\\\\ \")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### ACC print"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[126]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["omen"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ACCW_mean=np.round((metricW_df['ACC']*100).mean(),1)\n", "ACCW_low=np.round((metricW_df['ACC']*100).mean()-((1.96*(metricW_df['ACC']*100).std()/math.sqrt(len(metricW_df)))),1)\n", "ACCW_high=np.round((metricW_df['ACC']*100).mean()+((1.96*(metricW_df['ACC']*100).std()/math.sqrt(len(metricW_df)))),1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["en"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ACCM_mean=np.round((metricM_df['ACC']*100).mean(),1)\n", "ACCM_low=np.round((metricM_df['ACC']*100).mean()-((1.96*(metricM_df['ACC']*100).std()/math.sqrt(len(metricM_df)))),1)\n", "ACCM_high=np.round((metricM_df['ACC']*100).mean()+((1.96*(metricM_df['ACC']*100).std()/math.sqrt(len(metricM_df)))),1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["otal"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ACCT_mean=np.round((ACC_df['ACC']*100).mean(),1)\n", "ACCT_low=np.round((ACC_df['ACC']*100).mean()-((1.96*(ACC_df['ACC']*100).std()/math.sqrt(len(ACC_df)))),1)\n", "ACCT_high=np.round((ACC_df['ACC']*100).mean()+((1.96*(ACC_df['ACC']*100).std()/math.sqrt(len(ACC_df)))),1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[127]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\\\textbf{Female}: & \\\\textbf{\",ACCW_mean,\"} \\\\\\ \")\n", "print(f\"& ({ACCW_low}-{ACCW_high}) \\\\\\ \")\n", "print(\"\\\\textbf{Male}: & \\\\textbf{\",ACCM_mean,\"} \\\\\\ \")\n", "print(f\"& ({ACCM_low}-{ACCM_high}) \\\\\\ \")\n", "print(\"\\\\textbf{Total}: &\\\\textbf{\",ACCT_mean,\"} \\\\\\ \")\n", "print(f\"& ({ACCT_low}-{ACCT_high}) \\\\\\ \")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 80 pct. rule?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[492]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.mean(FNR_list_M)/np.mean(FNR_list_W)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## There doesn't seem to be bias between genders regarding classifications using either algorithm (LR, RF, SVM)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Age bias"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[493]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["age_group=pd.DataFrame((fall_data['BirthYear']>fall_data['BirthYear'].mean()).astype(int)) # the young ones are = 1\n", "age_group=age_group.rename(columns={\"BirthYear\":\"Age Group\"})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[494]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["age_group.sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[495]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X1 = fall_data.drop(columns=['Unnamed: 0','Fall']) # using all covariates in the dataset (no gender). \n", "#X1 = pd.DataFrame(preprocessing.scale(X1),columns=X1.columns)\n", "#X2 = pd.DataFrame(fall_data['Gender']) # gender in (not standardized)\n", "X3 = age_group\n", "X = pd.concat([X1,X3],axis=1)\n", "y1 = fall_data['Fall']\n", "y2 = age_group\n", "y = pd.concat([y1,y2],axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[496]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X.groupby('Age Group')['BirthYear'].mean()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[497]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import svm, datasets\n", "from sklearn.metrics import plot_confusion_matrix\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.model_selection import KFold"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Creating empty lists for:<br>\n", "TP/TN/FP/FN"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TP_list_old=[]\n", "TN_list_old=[]\n", "FP_list_old=[]\n", "FN_list_old=[]\n", "F1_list_old=[]\n", "ACC_list_old=[]\n", "TPR_list_old=[]\n", "TNR_list_old=[]\n", "FPR_list_old=[]\n", "FNR_list_old=[]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TP_list_young=[]\n", "TN_list_young=[]\n", "FP_list_young=[]\n", "FN_list_young=[]\n", "F1_list_young=[]\n", "ACC_list_young=[]\n", "TPR_list_young=[]\n", "TNR_list_young=[]\n", "FPR_list_young=[]\n", "FNR_list_young=[]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_names = ['No fall','Fall']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(1,11):\n", "    \n", "    \n", "    kf=KFold(n_splits=5, random_state=i, shuffle=True)\n", "    \n", "    for train_index, test_index in kf.split(X):\n", "        \n", "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n", "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n", "    \n", "    #### Flip fra den ene til den anden for at skifte mellem SVM, LR og RF ###\n", "    \n", "        #classifier = svm.SVC(kernel='rbf', C=1, random_state=0,class_weight='balanced').fit(X_train, y_train['Fall']) # not trained on Age Group var\n", "        classifier = LogisticRegression(max_iter=1000,class_weight='balanced').fit(X_train, y_train['Fall'])\n", "        #classifier = RandomForestClassifier(random_state=1).fit(X_train, y_train['Fall'])\n", "    \n", "        np.set_printoptions(precision=2)\n", "    # Plot non-normalized confusion matrix\n", "        titles_options = [(\"Confusion matrix, without normalization\", None)]\n", "    \n", "    \n", "        \n", "     ############ FOR WOMEN ################   \n", "        \n", "        for title, normalize in titles_options:\n", "            disp = plot_confusion_matrix(classifier, X_test[X_test['Age Group']==0],\n", "                                         y_test[y_test['Age Group']==0]['Fall'], \n", "                                     display_labels=class_names,\n", "                                     cmap=plt.cm.Blues, normalize=normalize)\n", "    \n", "        # getting TP/TN/FP/FN\n", "        TP=disp.confusion_matrix[1][1]\n", "        TN=disp.confusion_matrix[0][0]\n", "        FP=disp.confusion_matrix[0][1]\n", "        FN=disp.confusion_matrix[1][0]\n", "        F1=2*TP/(2*TP+FP+FN)\n", "        ACC=classifier.score(X_test[X_test['Age Group']==0], y_test[y_test['Age Group']==0]['Fall']) # mark gender\n", "        \n", "        # rates\n", "        FNR = FN/(FN+TP)\n", "        FPR = FP/(FP+TN)\n", "        TNR = TN/(TN+FP)\n", "        TPR = TP/(TP+FN)\n", "        \n", "        # appending to lists\n", "        TP_list_old.append(TP)\n", "        TN_list_old.append(TN)\n", "        FP_list_old.append(FP)\n", "        FN_list_old.append(FN)\n", "        F1_list_old.append(F1)\n", "        ACC_list_old.append(ACC)\n", "        TPR_list_old.append(TPR)\n", "        TNR_list_old.append(TNR)\n", "        FPR_list_old.append(FPR)\n", "        FNR_list_old.append(FNR)\n", "        \n", "        \n", "    ############ FOR MEN ################    \n", "        \n", "        \n", "        for title, normalize in titles_options:\n", "            disp = plot_confusion_matrix(classifier, X_test[X_test['Age Group']==1],\n", "                                         y_test[y_test['Age Group']==1]['Fall'], \n", "                                     display_labels=class_names,\n", "                                     cmap=plt.cm.Blues, normalize=normalize)\n", "    \n", "        # getting TP/TN/FP/FN\n", "        TP=disp.confusion_matrix[1][1]\n", "        TN=disp.confusion_matrix[0][0]\n", "        FP=disp.confusion_matrix[0][1]\n", "        FN=disp.confusion_matrix[1][0]\n", "        F1=2*TP/(2*TP+FP+FN)\n", "        ACC=classifier.score(X_test[X_test['Age Group']==1], y_test[y_test['Age Group']==1]['Fall']) # mark gender\n", "        \n", "        # rates\n", "        FNR = FN/(FN+TP)\n", "        FPR = FP/(FP+TN)\n", "        TNR = TN/(TN+FP)\n", "        TPR = TP/(TP+FN)\n", "        \n", "        # appending to lists\n", "        TP_list_young.append(TP)\n", "        TN_list_young.append(TN)\n", "        FP_list_young.append(FP)\n", "        FN_list_young.append(FN)\n", "        F1_list_young.append(F1)\n", "        ACC_list_young.append(ACC)\n", "        TPR_list_young.append(TPR)\n", "        TNR_list_young.append(TNR)\n", "        FPR_list_young.append(FPR)\n", "        FNR_list_young.append(FNR)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[498]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Mean of TPR for old:{round(np.mean(TPR_list_old)*100,1)}{round((np.mean(TPR_list_old)-(np.std(TPR_list_old)*1.96))*100,1),round((np.mean(TPR_list_old)+(np.std(TPR_list_old)*1.96))*100,1)}\")\n", "print(f\"Mean of FPR for old:{round(np.mean(FPR_list_old)*100,1)}{round((np.mean(FPR_list_old)-(np.std(FPR_list_old)*1.96))*100,1),round((np.mean(FPR_list_old)+(np.std(FPR_list_old)*1.96))*100,1)}\")\n", "print(f\"Mean of TNR for old:{round(np.mean(TNR_list_old)*100,1)}{round((np.mean(TNR_list_old)-(np.std(TNR_list_old)*1.96))*100,1),round((np.mean(TNR_list_old)+(np.std(TNR_list_old)*1.96))*100,1)}\")\n", "print(f\"Mean of FNR for old:{round(np.mean(FNR_list_old)*100,1)}{round((np.mean(FNR_list_old)-(np.std(FNR_list_old)*1.96))*100,1),round((np.mean(FNR_list_old)+(np.std(FNR_list_old)*1.96))*100,1)}\")\n", "print(f\"Mean of ACC for old:{round(np.mean(ACC_list_old)*100,1)}{round((np.mean(ACC_list_old)-(np.std(ACC_list_old)*1.96))*100,1),round((np.mean(ACC_list_old)+(np.std(ACC_list_old)*1.96))*100,1)}\")\n", "print(\"--------------------------------------------\")\n", "print(f\"Mean of TPR for young:{round(np.mean(TPR_list_young)*100,1)}{round((np.mean(TPR_list_young)-(np.std(TPR_list_young)*1.96))*100,1),round((np.mean(TPR_list_young)+(np.std(TPR_list_young)*1.96))*100,1)}\")\n", "print(f\"Mean of FPR for young:{round(np.mean(FPR_list_young)*100,1)}{round((np.mean(FPR_list_young)-(np.std(FPR_list_young)*1.96))*100,1),round((np.mean(FPR_list_young)+(np.std(FPR_list_young)*1.96))*100,1)}\")\n", "print(f\"Mean of TNR for young:{round(np.mean(TNR_list_young)*100,1)}{round((np.mean(TNR_list_young)-(np.std(TNR_list_young)*1.96))*100,1),round((np.mean(TNR_list_young)+(np.std(TNR_list_young)*1.96))*100,1)}\")\n", "print(f\"Mean of FNR for young:{round(np.mean(FNR_list_young)*100,1)}{round((np.mean(FNR_list_young)-(np.std(FNR_list_young)*1.96))*100,1),round((np.mean(FNR_list_young)+(np.std(FNR_list_young)*1.96))*100,1)}\")\n", "print(f\"Mean of ACC for young:{round(np.mean(ACC_list_young)*100,1)}{round((np.mean(ACC_list_young)-(np.std(ACC_list_young)*1.96))*100,1),round((np.mean(ACC_list_young)+(np.std(ACC_list_young)*1.96))*100,1)}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[499]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["omen"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TPR_final_old=[round(np.mean(TPR_list_old)*100,1),round((np.mean(TPR_list_old)-(np.std(TPR_list_old)*1.96))*100,1),round((np.mean(TPR_list_old)+(np.std(TPR_list_old)*1.96))*100,1)]\n", "FPR_final_old=[round(np.mean(FPR_list_old)*100,1),round((np.mean(FPR_list_old)-(np.std(FPR_list_old)*1.96))*100,1),round((np.mean(FPR_list_old)+(np.std(FPR_list_old)*1.96))*100,1)]\n", "TNR_final_old=[round(np.mean(TNR_list_old)*100,1),round((np.mean(TNR_list_old)-(np.std(TNR_list_old)*1.96))*100,1),round((np.mean(TNR_list_old)+(np.std(TNR_list_old)*1.96))*100,1)]\n", "FNR_final_old=[round(np.mean(FNR_list_old)*100,1),round((np.mean(FNR_list_old)-(np.std(FNR_list_old)*1.96))*100,1),round((np.mean(FNR_list_old)+(np.std(FNR_list_old)*1.96))*100,1)]\n", "ACC_final_old=[round(np.mean(ACC_list_old)*100,1),round((np.mean(ACC_list_old)-(np.std(ACC_list_old)*1.96))*100,1),round((np.mean(ACC_list_old)+(np.std(ACC_list_old)*1.96))*100,1)]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["en"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TPR_final_young=[round(np.mean(TPR_list_young)*100,1),round((np.mean(TPR_list_young)-(np.std(TPR_list_young)*1.96))*100,1),round((np.mean(TPR_list_young)+(np.std(TPR_list_young)*1.96))*100,1)]\n", "FPR_final_young=[round(np.mean(FPR_list_young)*100,1),round((np.mean(FPR_list_young)-(np.std(FPR_list_young)*1.96))*100,1),round((np.mean(FPR_list_young)+(np.std(FPR_list_young)*1.96))*100,1)]\n", "TNR_final_young=[round(np.mean(TNR_list_young)*100,1),round((np.mean(TNR_list_young)-(np.std(TNR_list_young)*1.96))*100,1),round((np.mean(TNR_list_young)+(np.std(TNR_list_young)*1.96))*100,1)]\n", "FNR_final_young=[round(np.mean(FNR_list_young)*100,1),round((np.mean(FNR_list_young)-(np.std(FNR_list_young)*1.96))*100,1),round((np.mean(FNR_list_young)+(np.std(FNR_list_young)*1.96))*100,1)]\n", "ACC_final_young=[round(np.mean(ACC_list_young)*100,1),round((np.mean(ACC_list_young)-(np.std(ACC_list_young)*1.96))*100,1),round((np.mean(ACC_list_young)+(np.std(ACC_list_young)*1.96))*100,1)]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[500]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"old: \\\\textbf{\",TPR_final_old[0],\"} & \\\\textbf{\",FPR_final_old[0],\"} & \\\\textbf{\",TNR_final_old[0],\"} & \\\\textbf{\",FNR_final_old[0],\"} & \\\\textbf{\",ACC_final_old[0],\"} \\\\\\ \")\n", "print(f\"({TPR_final_old[1]}-{TPR_final_old[2]}) & ({FPR_final_old[1]}-{FPR_final_old[2]}) & ({TNR_final_old[1]}-{TNR_final_old[2]}) & ({FNR_final_old[1]}-{FNR_final_old[2]}) & ({ACC_final_old[1]}-{ACC_final_old[2]}) \\\\\\ \")\n", "print(\"young: \\\\textbf{\",TPR_final_young[0],\"} & \\\\textbf{\",FPR_final_young[0],\"} & \\\\textbf{\",TNR_final_young[0],\"} & \\\\textbf{\",FNR_final_young[0],\"} & \\\\textbf{\",ACC_final_young[0],\"} \\\\\\ \")\n", "print(f\"({TPR_final_young[1]}-{TPR_final_young[2]}) & ({FPR_final_young[1]}-{FPR_final_young[2]}) & ({TNR_final_young[1]}-{TNR_final_young[2]}) & ({FNR_final_young[1]}-{FNR_final_young[2]}) & ({ACC_final_young[1]}-{ACC_final_young[2]}) \\\\\\ \")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 80 pct. rule"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[166]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.mean(FNR_list_old)/np.mean(FNR_list_young)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Result: as the citizens get older, the models does a worse job on them. For citizens above the mean age, there are more false negatives. In other words, the algorithm in a higher rate misclassifies the older part of the distribution by predicting that a fall would not occur when - in fact - the citizen did fall. <br>\n", "<br>\n", "## Although this is only really the case for SVM, a little bit for LR and not at all for RF.<br>\n", "<br>\n", "## But, nonetheless, it is problematic that the algorithms is worse for older citizens, since it is more of a problem if they fall!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Checking mean of fall pr. Birth Year to see if elderly fall more (as expected), could explain some of the discrepancy in rates. <br>\n", "### (MOVE ALL OF THIS IDDA TO ANOTHER NOTEBOOK)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[21]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[22]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import seaborn as sns\n", "sns.barplot(x=fall_data['BirthYear'],y=fall_data['Fall'],ci=None)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[23]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["age_fall_scat=pd.DataFrame(fall_data.groupby('BirthYear')['Fall'].mean()).reset_index()\n", "age_fall_scat.head(5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[24]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.scatterplot(x=age_fall_scat.BirthYear,y=age_fall_scat.Fall)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[25]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["age_fall_scat.corr(method='pearson') # with all ages"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[26]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["age_fall_scat_sub60 = age_fall_scat[age_fall_scat['BirthYear']<60]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[27]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.scatterplot(x=age_fall_scat_sub60.BirthYear,y=age_fall_scat_sub60.Fall)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[28]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["age_fall_scat_sub60.corr(method='pearson') # with all ages"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[29]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data['agegroup']=(fall_data['BirthYear']>36.88).astype(int) # young is one!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[30]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data.groupby('agegroup')['Fall'].mean()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[31]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.histplot(x=fall_data.Fall,hue=fall_data.agegroup,stat='density',common_norm=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### All this points towards that the older citizens actually do fall more than the younger ones. Although this does not mean that the mapping from actual falls to registered falls is not worse for the older citizens, since some of their falls lead to hospitalizations, and this might not be registered by DigiRehab. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Next up could be to do IDDA on number of Ats of the like. Older should have more Ats'."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[32]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[33]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data.groupby('agegroup')['NumberAts'].mean()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[34]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.histplot(x=fall_data.NumberAts,hue=fall_data.agegroup,stat='density',common_norm=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Aha! The young ones have more Ats, which does not really make sense.... "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[35]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data[['Gender','BirthYear','NumberAts','Fall']].corr(method='pearson') # with all ages"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### But, NumberAts is not positively correlated with falling..."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[36]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data[['1Ats','2Ats','3Ats','4Ats','5Ats','Fall']].corr(method='pearson')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[37]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["classifier_Ats = RandomForestClassifier(random_state=1).fit(X_train[['1Ats','2Ats','3Ats','4Ats','5Ats']], y_train['Fall'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[38]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["titles_options = [(\"Confusion matrix, without normalization\", None)]\n", "    \n", "    \n", "        \n", "     ############ FOR WOMEN ################   \n", "    \n", "for title, normalize in titles_options:\n", "    disp = plot_confusion_matrix(classifier_Ats, X_test[['1Ats','2Ats','3Ats','4Ats','5Ats']],\n", "                                 y_test['Fall'], \n", "                             display_labels=class_names,\n", "                             cmap=plt.cm.Blues, normalize=normalize)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ACC=classifier_Ats.score(X_test[['1Ats','2Ats','3Ats','4Ats','5Ats']],y_test['Fall'])\n", "ACC"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### The classifier using only the first five Ats is just as good as the one using all covariates"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Looking at the difference between the non-embedded and the embedded fall data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[39]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data_ori = pd.read_csv('/restricted/s161749/G2020-57-Aalborg-bias/Data_air/fall.csv')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[75]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data_ori['1Ats'].value_counts().head(5), fall_data_ori['1Ats'].value_counts().head(5).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[74]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data_ori['2Ats'].value_counts().head(5), fall_data_ori['2Ats'].value_counts().head(5).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[73]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data_ori['3Ats'].value_counts().head(5), fall_data_ori['3Ats'].value_counts().head(5).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[72]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data_ori['4Ats'].value_counts().head(5), fall_data_ori['4Ats'].value_counts().head(5).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[71]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fall_data_ori['5Ats'].value_counts().head(5), fall_data_ori['5Ats'].value_counts().head(5).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### If we use these six Ats numbers OHE for on the first six places we will match a lot of the observations: 120606, 93307, 0, 222718, 91218, 215103"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[244]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["80/100"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[245]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["100/80"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}