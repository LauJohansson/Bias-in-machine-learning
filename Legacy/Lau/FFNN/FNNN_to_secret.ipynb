{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[24]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ATH=\"/content/drive/My Drive/Kandidat speciale/500 - Notebooks/models/all races_CV50/\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## AIR ### "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["AIR=True\n", "file_name=\"fall_emb.csv\"\n", "full_file_path=\"/restricted/s164512/G2020-57-Aalborg-bias/data_air/\"+file_name"]}, {"cell_type": "markdown", "metadata": {}, "source": ["itel_mitigation=\"testAIR\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["titel_mitigation=\"test23may\"\n", "PATH_orig=\"/restricted/s164512/G2020-57-Aalborg-bias/lau/FFNN/models/\"+titel_mitigation+\"/\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_col_name=\"Fall\"\n", "X_col_names=['Gender', 'BirthYear', 'Cluster', 'LoanPeriod', 'NumberAts', '1Ats',\n", "       '2Ats', '3Ats', '4Ats', '5Ats', '6Ats', '7Ats', '8Ats', '9Ats', '10Ats',\n", "       '11Ats', '12Ats', '13Ats', '14Ats', '15Ats', '16Ats', '17Ats', '18Ats',\n", "       '19Ats', '20Ats', '21Ats', '22Ats', '23Ats', '24Ats', '25Ats', '26Ats',\n", "       '27Ats', '28Ats', '29Ats', '30Ats', '31Ats', '32Ats', '33Ats', '34Ats',\n", "       '35Ats', '36Ats', '37Ats', '38Ats', '39Ats', '40Ats', '41Ats', '42Ats',\n", "       '43Ats', '44Ats', '45Ats', '46Ats', '47Ats', '48Ats', '49Ats', '50Ats',]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["procted_col_name=\"Gender\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### COMPASS ####"]}, {"cell_type": "markdown", "metadata": {}, "source": ["IR=False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["itel_mitigation=\"testCOMPASS\"<br>\n", "ATH_orig=\"/restricted/s164512/G2020-57-Aalborg-bias/lau/FFNN/models/\"+titel_mitigation+\"/\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["ull_file_path = 'https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_col_name=\"is_recid\"<br>\n", "_col_names=['remember_index','sex','age','race', 'juv_fel_count','juv_misd_count','juv_other_count','priors_count',\"c_charge_desc\",\"c_charge_degree\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rocted_col_name=\"race\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[25]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_nodes=500"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["batch_size=40\n", "epochs=100\n", "p_drop=0.4"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optim_type=\"Adam\" #SGD\n", "lr=0.001 #0.001 er godt\n", "wd=0.003 #0.001 er godt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[26]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from tqdm.notebook import tqdm\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "#import torchvision.datasets as datasets\n", "from torch.utils.data import DataLoader\n", "#import torchvision.transforms as transforms\n", "import matplotlib.pyplot as plt\n", "import torch.optim as optim\n", "from IPython.display import clear_output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd \n", "import seaborn as sns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "plt.style.use('seaborn')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import plot_confusion_matrix\n", "from sklearn.metrics import confusion_matrix\n", "import matplotlib.patches as mpatches\n", "from matplotlib.patches import Patch\n", "from matplotlib.lines import Line2D"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from sklearn.model_selection import train_test_split\n", "from sklearn import preprocessing"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rom google.colab import drive"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import KFold"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from datetime import datetime"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pytz\n", "import random"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "from sklearn.model_selection import StratifiedKFold"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[27]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utils import *"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[28]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def loss_fn(target,predictions):\n", "    criterion = nn.BCELoss()\n", "    loss_out = criterion(predictions, target)\n", "    return loss_out"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[29]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def accuracy(true,pred):\n", "    acc = (true.float().round() == pred.float().round()).float().detach().cpu().numpy()\n", "    return float(100 * acc.sum() / len(acc))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_test():\n", "    avg_loss_ts = 0\n", "    avg_acc_ts=0\n", "    model.eval()  # train mode\n", "    for X_batch, Y_batch in data_ts:\n", "        X_batch = X_batch.to(device)\n", "        Y_batch = Y_batch.to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        # forward\n", "        Y_pred = model(X_batch.float()) \n", "        loss = loss_fn(Y_batch.float(), Y_pred.squeeze()) \n\n", "        # calculate metrics to show the user\n", "        avg_loss_ts += loss / len(data_ts)\n", "        avg_acc_ts+=accuracy(Y_batch,Y_pred.squeeze()) / len(data_ts)\n", "    #toc = time()\n", "    return avg_loss_ts, avg_acc_ts"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_all_time_low(all_time,new_val):\n", "    if all_time>new_val:\n", "        return new_val\n", "    else:\n", "        return all_time"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[30]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Network(nn.Module):\n", "    def __init__(self):\n", "        super(Network, self).__init__()\n", "        self.fully_connected1 = nn.Sequential(\n", "            nn.Linear(n_feat,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )\n", "        self.fully_connectednew = nn.Sequential(\n", "            nn.Linear(n_nodes,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )\n", "        self.fully_connectednew1 = nn.Sequential(\n", "            nn.Linear(n_nodes,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )\n", "        self.fully_connectednew2 = nn.Sequential(\n", "            nn.Linear(n_nodes,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )\n", "        self.fully_connectednew3 = nn.Sequential(\n", "            nn.Linear(n_nodes,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        self.fully_connected2 = nn.Sequential(\n", "            nn.Linear(n_nodes,output_dim),\n", "            #nn.Softmax(dim = 1)\n", "            nn.Sigmoid()\n", "            )\n", "    def forward(self, x):\n", "      #reshaping x so it becomes flat, except for the first dimension (which is the minibatch)\n", "        #x = x.view(x.size(0),-1)\n", "        x = self.fully_connected1(x)\n", "        x = self.fully_connectednew(x)\n", "        x = self.fully_connectednew1(x)\n", "        x = self.fully_connectednew2(x)\n", "        x = self.fully_connectednew3(x)\n", "        x = self.fully_connected2(x)\n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[36]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for overall_loop in [0,1,2,3,4,5,6,7,8,9]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    print(\"Running overall number \"+str(overall_loop))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    custom_seed=4\n", "    k_split=overall_loop\n", "    torch.manual_seed(custom_seed)\n", "    random.seed(custom_seed)\n", "    np.random.seed(custom_seed)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    seedName=\"model\"+str(k_split)#\n", "    PATH=PATH_orig+seedName+\"/\"\n", "    print(PATH)\n\n", "    #Make dir to files\n", "    if not os.path.exists(PATH):\n", "        os.makedirs(PATH)\n", "        print(\"Created new path!: \",PATH)\n", "    df2 = pd.read_csv(full_file_path)\n", "    df2[\"remember_index\"]=list(df2.index)\n\n", "    #df2.to_csv(PATH+\"/COMPASS_dataset.csv\")\n", "    \n", "    #Standarize\n", "    \n", "    X=df2[X_col_names+[\"remember_index\"]]\n", "    X_col_names_to_std = [name for name in X_col_names if not name in [procted_col_name]]\n", "    X[X_col_names_to_std] = pd.DataFrame(preprocessing.scale(X[X_col_names_to_std]),columns=X_col_names_to_std)\n", "    y=df2[[y_col_name,\"remember_index\"]]\n\n", "    #https://stackoverflow.com/questions/11587782/creating-dummy-variables-in-pandas-for-python\n", "    if AIR==False:\n", "        just_dummies=pd.get_dummies(X[['sex',\"race\",\"c_charge_desc\",\"c_charge_degree\"]])\n", "        X = pd.concat([X, just_dummies], axis=1) \n", "        X=X.drop(['sex',\"race\",\"c_charge_desc\",\"c_charge_degree\"] ,axis=1)\n", "    kf=KFold(n_splits=10, random_state=1, shuffle=True)\n", "    \n", "    \n", "    i=1\n", "    for train_index, val_index in kf.split(X):\n", "        if i==k_split:\n", "            break \n", "        i=i+1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        \n", "    \n", "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n", "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n", "    X_val, X_test, y_val, y_test = train_test_split(\n", "    X_val, y_val, test_size=0.5, random_state=1,shuffle=True)#,stratify=y_val[y_col_name]) #FJERN DENNE ,stratify=y[y_col_name])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #Save indexes of train, val, test\n", "    X_train_remember_index=X_train['remember_index']\n", "    X_val_remember_index=X_val['remember_index']\n", "    X_test_remember_index=X_test['remember_index']\n", "    X_r=X #these are used last in the notebook to test the data. It hold the true indeksing of the original data\n", "    y_r=y #these are used last in the notebook to test the data. It hold the true indeksing of the original data\n\n", "    #Remove the helper-column for remembering indexes\n", "    X=X.drop(columns=[\"remember_index\"])\n", "    X_train=X_train.drop(columns=[\"remember_index\"])\n", "    X_val=X_val.drop(columns=[\"remember_index\"])\n", "    X_test=X_test.drop(columns=[\"remember_index\"])\n", "    y=y.drop(columns=[\"remember_index\"])\n", "    y_train=y_train.drop(columns=[\"remember_index\"])\n", "    y_val=y_val.drop(columns=[\"remember_index\"])\n", "    y_test=y_test.drop(columns=[\"remember_index\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #Save as numpy array for the DATALOADER (PyTorch)\n", "    X_train=np.array(X_train[X.columns])\n", "    y_train=np.array(y_train[y_col_name])\n", "    X_val=np.array(X_val[X.columns])\n", "    y_val=np.array(y_val[y_col_name])\n", "    X_test=np.array(X_test[X.columns])\n", "    y_test=np.array(y_test[y_col_name])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #print(\"X_train shape: {}\".format(X_train.shape))\n", "    #print(\"y_train shape: {}\".format(y_train.shape))\n\n", "    #print(\"X_val shape: {}\".format(X_val.shape))\n", "    #print(\"y_val shape: {}\".format(y_val.shape))\n\n", "    #print(\"X_test shape: {}\".format(X_test.shape))\n", "    #print(\"y_test shape: {}\".format(y_test.shape))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    n_feat=X.shape[1]\n", "    output_dim=1 #binary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    data_tr = DataLoader(list(zip(X_train, y_train)), batch_size=batch_size, shuffle=False)\n", "    data_val = DataLoader(list(zip(X_val, y_val)), batch_size=batch_size, shuffle=False)\n", "    data_ts = DataLoader(list(zip(X_test, y_test)), batch_size=batch_size, shuffle=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "    #device=\"cpu\"\n", "    print(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    model = Network().to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    opt=optim.Adam(model.parameters(),lr=lr, weight_decay = wd)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #X_ts, Y_ts = next(iter(data_val))\n", "    #X_ts, Y_ts = X_ts.to(device), Y_ts.to(device)\n", "    epochnumber = []\n", "    all_train_losses = []\n", "    all_val_losses = []\n", "    all_ts_losses = []\n", "    all_train_acc=[]\n", "    all_val_acc=[]\n", "    all_ts_acc=[]\n", "    all_time_low_train_loss=1000\n", "    all_time_low_val_loss=1000\n", "    all_time_low_train_acc=1000\n", "    all_time_low_val_acc=1000"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    for epoch in range(epochs):\n", "        #tic = time()\n", "        if (epoch)%20==0:\n", "            print('* Epoch %d/%d' % (epoch+1, epochs))\n", "        epochnumber.append(epoch)\n", "        avg_loss_train = 0\n", "        avg_acc=0\n", "        model.train()  # train mode\n", "        for X_batch, Y_batch in data_tr:\n", "            X_batch = X_batch.to(device)\n", "            Y_batch = Y_batch.to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            # set parameter gradients to zero\n", "            opt.zero_grad()\n\n", "            # forward\n", "            Y_pred = model(X_batch.float()) #oprdindeligt havde vi 3 lag (RGB), nu har vi kun 1 (greyscale) -> \n", "            loss = loss_fn(Y_batch.float(), Y_pred.squeeze())  # forward-pass\n", "            loss.backward()  # backward-pass\n", "            opt.step()  # update weights\n\n", "            # calculate metrics to show the user\n", "            avg_loss_train += loss / len(data_tr)\n", "            avg_acc+=accuracy(Y_batch,Y_pred.squeeze()) / len(data_tr)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        #toc = time()\n", "        all_time_low_train_loss=get_all_time_low(all_time_low_train_loss,avg_loss_train)\n", "        all_time_low_train_acc=get_all_time_low(all_time_low_train_acc,avg_acc)\n", "          #print(' - train loss: %f' % avg_loss_train)\n", "          #print(' - train acc: {} %'.format(round(avg_acc,2)))\n", "        all_train_losses.append(avg_loss_train)\n", "        all_train_acc.append(avg_acc)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        with torch.no_grad():\n", "            avg_loss_val = 0\n", "            avg_acc_val=0\n", "            model.eval()  # train mode\n", "            for X_batch, Y_batch in data_val:\n", "                X_batch = X_batch.to(device)\n", "                Y_batch = Y_batch.to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                # forward\n", "                Y_pred = model(X_batch.float()) #oprdindeligt havde vi 3 lag (RGB), nu har vi kun 1 (greyscale) -> \n", "                loss = loss_fn(Y_batch.float(), Y_pred.squeeze())  # forward-pass\n", "                # calculate metrics to show the user\n", "                avg_loss_val += loss / len(data_val)\n", "                avg_acc_val+=accuracy(Y_batch,Y_pred.squeeze()) / len(data_val)\n", "            #toc = time()\n", "            all_time_low_val_loss=get_all_time_low(all_time_low_val_loss,avg_loss_val)\n", "            all_time_low_val_acc=get_all_time_low(all_time_low_val_acc,avg_acc_val)\n", "            #print(' - val loss: %f' % avg_loss_val)\n", "            #print(' - val acc: {} %'.format(round(avg_acc_val,2)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            ########Save model####\n", "            \n", "        if  epoch == 0 or avg_loss_val <= min(all_val_losses) :\n", "            torch.save(model.state_dict(), PATH+'_FFNN_model_local.pth')\n", "            print('####Saved model####')\n", "        all_val_losses.append(avg_loss_val)\n", "        all_val_acc.append(avg_acc_val)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["      ###PLOT########\n", "    if epoch==epochs-1:\n", "        #Save the last epoch\n", "        torch.save(model.state_dict(), PATH+'_FFNN_model_global.pth')\n\n", "        #take the best model (with lowest validation loss)\n", "        #model.load_state_dict(torch.load(PATH+seedName+'_FFNN_model_local.pth'))\n", "        model.eval()\n", "        all_ts_losses=[get_test()[0]] * (epoch+1)\n", "        all_ts_acc=[get_test()[1]] * (epoch+1)\n", "        plt.figure(1)\n", "        plt.plot(epochnumber, all_train_losses, 'r', epochnumber, all_val_losses, 'b',epochnumber, all_ts_losses, '--')\n", "        plt.xlabel('Epochs'), plt.ylabel('Loss')\n", "        plt.legend(['Train Loss', 'Val Loss','Test loss'])\n", "        plt.savefig(PATH+'_loss.png')\n", "        plt.show()\n", "        plt.figure(2)\n", "        plt.plot(epochnumber, all_train_acc, 'black', epochnumber, all_val_acc, 'grey',epochnumber, all_ts_acc, '--')\n", "        plt.xlabel('Epochs'), plt.ylabel('Accuracy')\n", "        plt.legend(['Train acc', 'Val acc','Test acc'])\n", "        plt.savefig(PATH+'_acc.png')\n", "        #plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        #print('####Saved model####')\n", "        metrics=pd.DataFrame({\"all_time_low_train_loss\":[all_time_low_train_loss.item()],\n", "                              \"all_time_low_train_acc\":[all_time_low_train_acc],\n", "                          \"all_time_low_val_loss\":[all_time_low_val_loss.item()],\n", "                              \"all_time_val_train_acc\":[all_time_low_val_acc],\n", "                          \"test_acc\":[all_ts_acc[0]],\n", "                          \"test_loss\":[all_ts_losses[0].item()]\n", "                                            })\n", "        metrics.to_csv( PATH+'_metrics.csv')\n", "      #clear_output(wait=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    for local_best in [0,1]:\n", "        #local_best=0\n", "        model1 = Network().to(device)\n", "        if local_best==1:\n", "            model1.load_state_dict(torch.load(PATH+'_FFNN_model_local.pth'))\n", "        else:\n", "            model1.load_state_dict(torch.load(PATH+'_FFNN_model_global.pth'))\n", "        model1.eval()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        X_to_test=X_r[X_r[\"remember_index\"].isin(X_test_remember_index)]\n", "        y_to_test=y_r[X_r[\"remember_index\"].isin(X_test_remember_index)]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        X_to_test=X_to_test.drop(columns=\"remember_index\")\n", "        y_to_test=y_to_test.drop(columns=\"remember_index\")\n", "        df_evaluate = X_to_test\n", "        df_evaluate[y_col_name]=y_to_test\n", "        df_evaluate[procted_col_name]=df2[X_r[\"remember_index\"].isin(X_test_remember_index)][procted_col_name]\n", "        if AIR==False:\n", "            cols= [col for col in list(df_evaluate.columns) if col not in [y_col_name,\"sex\",\"age_cat\",\"race\",\"c_charge_desc\",\"c_charge_degree\"]]\n", "        else:\n", "            cols= [col for col in list(df_evaluate.columns) if col not in [y_col_name]]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        X_numpy=np.array(df_evaluate[cols])\n", "        X_torch=torch.tensor(X_numpy)\n", "        y_pred = model1(X_torch.float().to(device))\n", "        \n", "        list_of_output=[round(a.item(),0) for a in y_pred.detach().cpu()]\n", "        \n", "        df_evaluate[\"output\"]=list_of_output\n", "        \n", "        \n", "        ##SAVING THE TEST DATA\n", "        if local_best==1:\n", "            df_evaluate.to_csv(PATH+\"test_data_localmodel.csv\")\n", "        else:\n", "            df_evaluate.to_csv(PATH+\"test_data_globalmodel.csv\")\n", "        ######################\n", "        df_for_plot=get_df_w_metrics(df_evaluate,procted_col_name,y_col_name,\"output\")\n", "        \n", "        if local_best==1:\n", "            df_for_plot.to_csv(PATH+\"_\"+procted_col_name+\"_stats_local.csv\")\n", "        else:\n", "            df_for_plot.to_csv(PATH+\"_\"+procted_col_name+\"_stats_global.csv\")\n", "        df_evaluate_together=df_evaluate\n", "        df_evaluate_together[procted_col_name]=\"all\"\n", "        df_for_plot_all=get_df_w_metrics(df_evaluate_together,procted_col_name,y_col_name,\"output\")\n", "        if local_best==1:\n", "            df_for_plot_all.to_csv(PATH+\"_all_stats_local.csv\")\n", "        else:\n", "            df_for_plot_all.to_csv(PATH+\"_all_stats_global.csv\")\n", "        #%reset -f"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": [" # GLOBAL ALL"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[46]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["column_names = [\"Group\", \"ML\", \"Measure\",\"Value\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_out = pd.DataFrame(columns = column_names)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in [0,1,2,3,4,5,6,7,8,9]:\n", "  \n", "    PATH_loop=PATH_orig+\"model\"+str(i)+\"/_all_stats_global.csv\"\n", "  \n", "    data=pd.read_csv(PATH_loop)\n", "    for group in [\"all\"]:\n", "        for measure in ['FPR', 'FNR', 'ACC', 'F1', 'FDR', 'LRminus','LRplus', 'NPV', 'PPV', 'TNR', 'TPR','TP','TN','FN','FP']:\n", "            value=float(data[data[procted_col_name]==group][measure])\n", "            df_out=df_out.append({'Group': group,\"ML\":\"FFNN\"+str(i),\"Measure\":measure,\"Value\":value}, ignore_index=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_out.to_csv(PATH_orig+\"/FFNN_metrics_crossvalidated_global_all.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[47]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["global_all_bar=sns.barplot(data=df_out[df_out[\"Measure\"].isin([\"FPR\",\"FNR\",\"TPR\",\"TNR\"])],x=\"Group\", y=\"Value\", ci=95,hue=\"Measure\")\n", "global_all_bar.set_title('Global all')\n", "global_all_bar.get_figure().savefig(PATH_orig+\"/barplot_global_all.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# LOCAL ALL"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[48]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["column_names = [\"Group\", \"ML\", \"Measure\",\"Value\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_out = pd.DataFrame(columns = column_names)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in [0,1,2,3,4,5,6,7,8,9]:\n", "    PATH_loop=PATH_orig+\"model\"+str(i)+\"/_all_stats_local.csv\"\n", "  \n", "    data=pd.read_csv(PATH_loop)\n", "    for group in [\"all\"]:\n", "        for measure in ['FPR', 'FNR', 'ACC', 'F1', 'FDR', 'LRminus','LRplus', 'NPV', 'PPV', 'TNR', 'TPR','TP','TN','FN','FP']:\n", "            value=float(data[data[procted_col_name]==group][measure])\n", "            df_out=df_out.append({'Group': group,\"ML\":\"FFNN\"+str(i),\"Measure\":measure,\"Value\":value}, ignore_index=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_out.to_csv(PATH_orig+\"FFNN_metrics_crossvalidated_local_all.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[49]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["local_all_bar=sns.barplot(data=df_out[df_out[\"Measure\"].isin([\"FPR\",\"FNR\",\"TPR\",\"TNR\"])],x=\"Group\", y=\"Value\", ci=95,hue=\"Measure\")\n", "local_all_bar.set_title('Global all')\n", "local_all_bar.get_figure().savefig(PATH_orig+\"/barplot_local_all.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Global protected"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[50]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["column_names = [\"Group\", \"ML\", \"Measure\",\"Value\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_out = pd.DataFrame(columns = column_names)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in [0,1,2,3,4,5,6,7,8,9]:\n", "    PATH_loop=PATH_orig+\"model\"+str(i)+\"/_\"+procted_col_name+\"_stats_global.csv\"\n", "  \n", "    data=pd.read_csv(PATH_loop)\n", "    for group in list(data[procted_col_name].unique()):\n", "        for measure in ['FPR', 'FNR', 'ACC', 'F1', 'FDR', 'LRminus','LRplus', 'NPV', 'PPV', 'TNR', 'TPR','TP','TN','FN','FP']:\n", "            value=float(data[data[procted_col_name]==group][measure])\n", "            df_out=df_out.append({'Group': group,\"ML\":\"FFNN\"+str(i),\"Measure\":measure,\"Value\":value}, ignore_index=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_out.to_csv(PATH_orig+\"FFNN_metrics_crossvalidated_global_\"+procted_col_name+\".csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[51]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["global_proc_bar=sns.barplot(data=df_out[df_out[\"Measure\"].isin([\"FPR\",\"FNR\",\"TPR\",\"TNR\"])],x=\"Group\", y=\"Value\", ci=95,hue=\"Measure\")\n", "global_proc_bar.set_title('Global proctected: '+procted_col_name)\n", "global_proc_bar.get_figure().savefig(PATH_orig+\"/barplot_global_proc.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Local protected"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[52]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["column_names = [\"Group\", \"ML\", \"Measure\",\"Value\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_out = pd.DataFrame(columns = column_names)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in [0,1,2,3,4,5,6,7,8,9]:\n", "    PATH_loop=PATH_orig+\"model\"+str(i)+\"/_\"+procted_col_name+\"_stats_local.csv\"\n", "  \n", "    data=pd.read_csv(PATH_loop)\n", "    for group in list(data[procted_col_name].unique()):\n", "        for measure in ['FPR', 'FNR', 'ACC', 'F1', 'FDR', 'LRminus','LRplus', 'NPV', 'PPV', 'TNR', 'TPR','TP','TN','FN','FP']:\n", "            value=float(data[data[procted_col_name]==group][measure])\n", "            df_out=df_out.append({'Group': group,\"ML\":\"FFNN\"+str(i),\"Measure\":measure,\"Value\":value}, ignore_index=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_out.to_csv(PATH_orig+\"FFNN_metrics_crossvalidated_local_\"+procted_col_name+\".csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[53]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["local_proc_bar=sns.barplot(data=df_out[df_out[\"Measure\"].isin([\"FPR\",\"FNR\",\"TPR\",\"TNR\"])],x=\"Group\", y=\"Value\", ci=95,hue=\"Measure\")\n", "local_proc_bar.set_title('Local protected: '+procted_col_name)\n", "local_proc_bar.get_figure().savefig(PATH_orig+\"/barplot_local_proc.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Save all test data (and output)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[54]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for file_name in [\"localmodel\",\"globalmodel\"]:\n", "    test_data_0 = pd.read_csv(PATH_orig+\"model0/test_data_\"+file_name+\".csv\")\n", "    test_data_1 = pd.read_csv(PATH_orig+\"model1/test_data_\"+file_name+\".csv\")\n", "    test_data_2 = pd.read_csv(PATH_orig+\"model2/test_data_\"+file_name+\".csv\")\n", "    test_data_3 = pd.read_csv(PATH_orig+\"model3/test_data_\"+file_name+\".csv\")\n", "    test_data_4 = pd.read_csv(PATH_orig+\"model4/test_data_\"+file_name+\".csv\")\n", "    test_data_5 = pd.read_csv(PATH_orig+\"model5/test_data_\"+file_name+\".csv\")\n", "    test_data_6 = pd.read_csv(PATH_orig+\"model6/test_data_\"+file_name+\".csv\")\n", "    test_data_7 = pd.read_csv(PATH_orig+\"model7/test_data_\"+file_name+\".csv\")\n", "    test_data_8 = pd.read_csv(PATH_orig+\"model8/test_data_\"+file_name+\".csv\")\n", "    test_data_9 = pd.read_csv(PATH_orig+\"model9/test_data_\"+file_name+\".csv\")\n", "    df2=    pd.concat([test_data_0,\n", "                        test_data_1,\n", "                        test_data_2,\n", "                        test_data_3,\n", "                        test_data_4,\n", "                        test_data_5,\n", "                        test_data_6,\n", "                        test_data_7,\n", "                        test_data_8,\n", "                        test_data_9\n", "                       ],sort=False,axis=0)\n", "    df2.to_csv(PATH_orig+\"all_test_data_\"+file_name+\".csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}