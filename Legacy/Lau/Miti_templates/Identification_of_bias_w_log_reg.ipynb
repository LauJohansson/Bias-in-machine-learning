{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[246]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import random"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Load data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Logistic Reg"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_cols=[name for name in merged.columns.tolist() if name not in [\"Fall\",\"BorgerId\"]]<br>\n", "=merged[X_cols]<br>\n", "=merged[\"Fall\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_train, df_test = train_test_split(merged, test_size=0.25)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = df_train.drop(columns=['Fall','Gender_string'], axis=1) #drop Sex (protected) and paymant (y)\n", "X_test = df_test.drop(columns=['Fall','Gender_string'], axis=1)  #drop Sex (protected) and paymant (y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_train = df_train['Fall']\n", "y_test = df_test['Fall']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = LogisticRegression()\n", "model.fit(X_train, y_train)\n", "model.score(X_test, y_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": [""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[247]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_true=np.random.randint(2, size=100)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[248]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred=np.random.randint(2, size=100)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[249]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["gs=[\"Male\",\"Female\"]\n", "gender_list=[ random.choice(gs) for i in range(100)]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[250]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["raw = np.random.choice(list_of_candidates, number_of_items_to_pick,<br>\n", "             p=probability_distribution)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_true = [np.random.choice([0,1], 1,p=[0.8,0.2])[0] if gender==\"Female\" else np.random.choice([0,1], 1,p=[0.2,0.8])[0] for gender in gender_list  ]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[251]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["d = {'y_true': y_true, 'y_pred': y_pred,'Gender':gender_list,}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data=pd.DataFrame(d\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[252]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["@title get_df_w_metric(double click to expand)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_df_w_metrics(df,protected_variable_name,y_target_name,y_pred_name):\n", "    \"\"\"\n", "    This function takes a dataframe (df), and returns FPR/FNR for each value in the protected variable\n", "    Input: \n", "        df:                         a dataframe\n", "        protected_variable_name:    the name of the protected variable in the df\n", "        y_target_name:              the name of the target variable in the df\n", "        y_pred_name:                the name of the predticted variable in the df\n", "    \"\"\"\n\n", "    #Create empty DataFrame\n", "    confusion_df=pd.DataFrame(columns=[protected_variable_name,\"FPR\",\"FNR\"])\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #For each value of the protected variable, calculated FPR/FNR and insert into the empty DataFrame\n", "    for name in list(df[protected_variable_name].unique()):\n", "        a=df[df[protected_variable_name]==name][y_target_name]\n", "        b=df[df[protected_variable_name]==name][y_pred_name]#.apply(lambda x: 0 if x<t else 1 )\n", "    \n", "        TN, FP, FN, TP = confusion_matrix(list(a), list(b),labels=[0, 1]).ravel()\n", "        \n", "        # Sensitivity, hit rate, recall, or true positive rate\n", "        TPR = TP/(TP+FN)\n", "        # Specificity or true negative rate\n", "        TNR = TN/(TN+FP) \n", "        # Precision or positive predictive value\n", "        PPV = TP/(TP+FP)\n", "        # Negative predictive value\n", "        NPV = TN/(TN+FN)\n", "        # Fall out or false positive rate\n", "        FPR = FP/(FP+TN)\n", "        # False negative rate\n", "        FNR = FN/(TP+FN)\n", "        # False discovery rate\n", "        FDR = FP/(TP+FP)\n\n", "        # Overall accuracy\n", "        ACC = (TP+TN)/(TP+FP+FN+TN)\n", "        LRplus=TPR/FPR\n", "        LRminus=FNR/TNR"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        #F1-score\n", "        F1=2*(PPV*TPR)/(PPV+TPR)\n", "        confusion_df=confusion_df.append({protected_variable_name:name,\n", "                                          \"TPR\":TPR,\n", "                                          \"TNR\":TNR,\n", "                                          \"FPR\":FPR,\n", "                                          \"FNR\":FNR,\n", "                                          \"PPV\":PPV,\n", "                                          \"NPV\":NPV,\n", "                                          \"FDR\":FDR,\n", "                                          \"ACC\":ACC,\n", "                                          \"F1\":F1,\n", "                                          \"LRplus\":LRplus,\n", "                                          \"TN\":TN,\n", "                                          \"FP\":FP,\n", "                                          \"FN\":FN,\n", "                                          \"TP\":TP\n", "                                          },ignore_index=True)\n", "    return confusion_df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[253]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rom: https://nbviewer.jupyter.org/github/srnghn/bias-mitigation-examples/blob/master/Bias%20Mitigation%20with%20Disparate%20Impact%20Remover.ipynb"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def calc_prop(data, group_col, group, output_col, output_val):\n", "    '''\n", "    data:       The dataframe\n", "    group_col:  The protected atrtibute column (e.g Gender)\n", "    group:      The chosen group (e.g Male or Female)\n", "    output_col: The column holding the y-value (either y_hat or y   - could be Fall)\n", "    output_val: The value of the y  (e.g.   all y=1 )\n", "    \n", "    \n", "    Example:\n", "    \n", "    Find p(y=0 | G=\"Female\")\n", "    \n", "    calc_prop(data,\"Gender\",\"Female\",\"y_true\",0)\n", "    \n", "    \n", "    \n", "    '''\n", "    new = data[data[group_col] == group]\n", "    return len(new[new[output_col] == output_val])/len(new)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[254]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def calc_prop_no_group(data, output_col, output_val):\n", "    return len(data[data[output_col] == output_val])/len(data)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[255]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["est"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["calc_prop(data,\"Gender\",\"Female\",\"y_true\",0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[256]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def compare_bias_metrics(data,protected_variable_name,y_target_name,y_pred_name,unfavourable_name,favourable_name,print_var=False,fav_value=1,unfav_value=0):\n", "    \n", "    \n", "    df = get_df_w_metrics(data,protected_variable_name,y_target_name,y_pred_name)\n", "    \n", "    \n", "    \n", "    #==================== DISPARATE IMPACT ======================#\n", "    #Feldman et al\n", "    \n", "    #a1=data[y_target_name]\n", "    #b1=data[protected_variable_name]#.apply(lambda x: 0 if x<t else 1 )\n", "    #d, b, c, a = confusion_matrix(list(a1), list(b1),labels=[0, 1]).ravel()\n", "    \n", "    a=calc_prop(data,protected_variable_name,unfavourable_name,y_target_name,unfav_value) #prop of unfav group, recieve unfav value\n", "    b=calc_prop(data,protected_variable_name,favourable_name,y_target_name,unfav_value) #prop of ufav group, recieve unfav value\n", "    c=calc_prop(data,protected_variable_name,unfavourable_name,y_target_name,fav_value) #prop of ufav group, recieve fav value\n", "    d=calc_prop(data,protected_variable_name,favourable_name,y_target_name,fav_value) #prop of ufav group, recieve fav value\n", "    \n", "    \n", "    #a=df[df[protected_variable_name]==unfavourable_name][\"TN\"].item()\n", "    #b=df[df[protected_variable_name]==favourable_name][\"TN\"].item()\n", "    #c=df[df[protected_variable_name]==unfavourable_name][\"TP\"].item()\n", "    #d=df[df[protected_variable_name]==favourable_name][\"TP\"].item()\n", "        \n", "    Feldman_Disparate_impact=(c/(a + c)) / (d/(b + d))\n", "    \n", "    if print_var:\n", "        print(\"==================================== Feldman et al ====================================\")\n", "        \n", "        print(f\"If DATASET has no disparate impact then DI>=0.8.\")\n", "        print(f\"DI={Feldman_Disparate_impact}\")\n", "        \n", "        if Feldman_Disparate_impact>=0.8:\n", "            print(\"The DATASET has no disparate impact\")\n", "        else:\n", "            print(\"The DATASET has disparate impact\")\n", "        print(\"======================================================================================= \\n\")\n", "            \n", "    #===========================================================#\n", "    \n", "    \n", "    #==================== Learning Fair representations ======================#\n", "    #Zafar et al\n", "    \n", "    ###Disparate TREATMENT ####\n", "    \n", "    p_yhat1_z1=calc_prop(data,protected_variable_name,favourable_name,y_pred_name,fav_value)\n", "    p_yhat1_z0=calc_prop(data,protected_variable_name,unfavourable_name,y_pred_name,fav_value)\n", "    p_yhat1=calc_prop_no_group(data, y_pred_name, fav_value)\n", "    \n", "    p_yhat0_z1=calc_prop(data,protected_variable_name,favourable_name,y_pred_name,unfav_value)\n", "    p_yhat0_z0=calc_prop(data,protected_variable_name,unfavourable_name,y_pred_name,unfav_value)\n", "    p_yhat0=calc_prop_no_group(data, y_pred_name, unfav_value)\n", "    \n", "    \n", "    ###Disparate IMPACT ####\n", "    \n", "    if print_var:\n", "        print(\"==================================== Zafar et al ====================================\")\n", "        \n", "        print(f\"If the CLASSIFIER has no DISPARATE TREATMENT, these equations should hold:\")\n", "        print(f\"P(y_hat=1|z={favourable_name},x) = P(y_hat=1,x) <=> {round(p_yhat1_z1,2)} = {round(p_yhat1,2)}\")\n", "        print(f\"P(y_hat=1|z={unfavourable_name},x) = P(y_hat=1,x) <=> {round(p_yhat1_z0,2)} = {round(p_yhat1,2)}\")\n", "        print(f\"P(y_hat=0|z={favourable_name},x) = P(y_hat=0,x) <=> {round(p_yhat0_z1,2)} = {round(p_yhat0,2)}\")\n", "        print(f\"P(y_hat=0|z={unfavourable_name},x) = P(y_hat=0,x) <=> {round(p_yhat0_z0,2)} = {round(p_yhat0,2)}\")\n", "        print(\"\\n\")\n", "        \n", "        print(f\"If the CLASSIFIER has no DISPARATE IMPACT, these equations should hold:\")\n", "        print(f\"P(y_hat=1|z={unfavourable_name}) = P(y_hat=1,z={favourable_name}) <=> {round(p_yhat1_z0,2)} = {round(p_yhat1_z1,2)}\")\n", "        print(\"\\n\")\n", "        \n", "        print(f\"If the CLASSIFIER has no DISPARATE MISTREATMENT, these equations should hold:\")\n", "        \n", "        FPR_z0=df[df[protected_variable_name]==unfavourable_name][\"FPR\"].item()\n", "        FPR_z1=df[df[protected_variable_name]==favourable_name][\"FPR\"].item()\n", "        \n", "        FNR_z0=df[df[protected_variable_name]==unfavourable_name][\"FNR\"].item()\n", "        FNR_z1=df[df[protected_variable_name]==favourable_name][\"FNR\"].item()\n", "        \n", "        \n", "        \n", "        print(f\"FPR: P(y_hat!=y|z={unfavourable_name},y=0) = P(y_hat!=y|z={favourable_name},y=0) <=> {round(FPR_z0,2)} = {round(FPR_z1,2)}\")\n", "        print(f\"FNR: P(y_hat!=y|z={unfavourable_name},y=1) = P(y_hat!=y|z={favourable_name},y=1) <=> {round(FNR_z0,2)} = {round(FNR_z1,2)}\")\n", "        \n", "        print(\"======================================================================================= \\n\")\n", "    \n", "    \n", "    \n", "    \n", "    \n", "    #==================== Equality of Opportunity in Supervised Learning ======================#\n", "    #Hardt et al\n", "    \n", "    ### Equalized odds ####\n", "    \n", "    TPR_z0=df[df[protected_variable_name]==unfavourable_name][\"TPR\"].item()\n", "    TPR_z1=df[df[protected_variable_name]==favourable_name][\"TPR\"].item()\n", "    \n", "    TNR_z0=df[df[protected_variable_name]==unfavourable_name][\"TNR\"].item()\n", "    TNR_z1=df[df[protected_variable_name]==favourable_name][\"TNR\"].item()\n", "    \n", "    if print_var:\n", "        print(\"==================================== Hardt et al ====================================\")\n", "        \n", "        print(f\"If the CLASSIFIER has EQUALIZED ODDS, these equations should hold:\")\n", "        print(f\"P(y_hat=1|z={unfavourable_name},y=1) = P(y_hat=1|z={favourable_name},y=1) <=> {round(TPR_z0,2)} = {round(TPR_z1,2)}\")\n", "        print(f\"P(y_hat=0|z={unfavourable_name},y=0) = P(y_hat=0|z={favourable_name},y=0) <=> {round(TNR_z0,2)} = {round(TNR_z1,2)}\")\n", "        print(\"\\n\")\n", "        \n", "        print(f\"If the CLASSIFIER has EQUAL OPPORTUNITY, these equations should hold:\")\n", "        print(f\"P(y_hat=1|z={unfavourable_name},y=1) = P(y_hat=1|z={favourable_name},y=1) <=> {round(TPR_z0,2)} = {round(TPR_z1,2)}\")\n", "        print(\"\\n\")\n", "    \n", "        print(\"======================================================================================= \\n\")\n", "    \n", "    \n", "    ############Measuring racial discrimination in algorithms####\n", "    #Arnold et al. \n", "    \n", "    \n", "    \n", "    if print_var:\n", "        print(\"==================================== Arnold et al ====================================\")\n", "        \n", "        my=data[y_target_name].mean()\n", "        delta=(TNR_z1-TNR_z0)*(1-my)+(FNR_z1-FNR_z0)*my\n", "        \n", "        \n", "        print(f\"The racial discrimination paramenter (delta) = {delta}\")\n", "        print(\"\\n\")\n", "    \n", "        print(\"======================================================================================= \\n\")\n", "    \n", "        \n", "        \n", "        \n", "        \n", "    ############GENERAL CLASSIFICATION METRICS####\n", "    \n", "    \n", "    \n", "    if print_var:\n", "        print(\"==================================== GENERAL CLASSIFICATION METRICS ====================================\")\n", "        \n", "        print(f\"TPR for {unfavourable_name}: {TPR_z0}\")\n", "        print(f\"TPR for {favourable_name}: {TPR_z1}\")\n", "        print(\"\\n\")\n", "        \n", "        print(f\"TNR for {unfavourable_name}: {TNR_z0}\")\n", "        print(f\"TNR for {favourable_name}: {TNR_z1}\")\n", "        print(\"\\n\")\n", "        \n", "        print(f\"FPR for {unfavourable_name}: {FPR_z0}\")\n", "        print(f\"FPR for {favourable_name}:  {FPR_z1}\")\n", "        print(\"\\n\")\n", "        \n", "        print(f\"FNR for {unfavourable_name}:  {FNR_z0}\")\n", "        print(f\"FNR for {favourable_name}:  {FNR_z1}\")\n", "        print(\"\\n\")\n", "    \n", "        print(\"======================================================================================= \\n\")\n", "    \n", "        \n", "        \n", "        \n", "    \n", "    \n", "    \n", "    return Feldman_Disparate_impact\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[257]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["metrics=compare_bias_metrics(data=data,\n", "                        protected_variable_name=\"Gender\",\n", "                        y_target_name=\"y_true\",\n", "                        y_pred_name=\"y_pred\",\n", "                        unfavourable_name=\"Female\",\n", "                        favourable_name=\"Male\",\n", "                        print_var=True\n", "                        \n", "                       )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}