{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[23]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "import numpy as np\n", "import config as cfg\n", "import pandas as pd\n", "from tools import file_reader, file_writer, explainer\n", "from utility import metrics\n", "from sklearn.metrics import accuracy_score, precision_score\n", "from sklearn.metrics import recall_score, roc_auc_score\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.model_selection import train_test_split\n", "import xgboost as xgb\n", "import os\n", "from sklearn.metrics import confusion_matrix\n", "import seaborn as sns\n", "from sklearn import preprocessing"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[24]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utils_copy import *"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[25]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["procted_col_name=\"Gender\"\n", "y_col_name=\"Fall\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[26]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pathRoot=\"../../Data_air/\"\n", "pathFall=pathRoot+\"Fall.csv\"\n", "df=pd.read_csv(pathFall)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[27]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["titel_mitigation=\"test23may\"\n", "PATH_orig=\"/restricted/s164512/G2020-57-Aalborg-bias/lau/Xgboost/models/\"+titel_mitigation+\"/\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PATH=PATH_orig#+seedName+\"/\"\n", "print(PATH)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ake dir to files"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if not os.path.exists(PATH):\n", "    os.makedirs(PATH)\n", "    print(\"Created new path!: \",PATH)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[28]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[30]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_dir = cfg.FALL_XGB_DIR\n", "target_name = \"Fall\"\n", "        \n", "    \n", "df = df.sample(frac=1, random_state=0).reset_index(drop=True)\n", "    \n", "X = df.drop([target_name], axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_col_names_to_std = [name for name in X.columns if not name in [procted_col_name]]\n", "X[X_col_names_to_std] = pd.DataFrame(preprocessing.scale(X[X_col_names_to_std]),columns=X_col_names_to_std)\n", "y = df[target_name]\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n", "                                                            stratify=y, random_state=0)\n", "        "]}, {"cell_type": "markdown", "metadata": {}, "source": ["ATA_DIR = cfg.PROCESSED_DATA_DIR<br>\n", "ASES = [\"Complete\", \"Compliance\", \"Fall\", \"Fall_test\"]      <br>\n", "f = file_reader.read_csv(DATA_DIR, 'fall_emb.csv')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[31]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["neg, pos = np.bincount(y)\n", "scale_pos_weight = neg / pos"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["params = {\"n_estimators\": 400,\n", "        \"objective\": \"binary:logistic\",\n", "        \"scale_pos_weight\": scale_pos_weight,\n", "        \"use_label_encoder\": False,\n", "        \"learning_rate\": 0.1,\n", "        \"eval_metric\": \"logloss\",\n", "        \"seed\": 0\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[32]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = xgb.XGBClassifier(**params)\n", "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[33]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_test=pd.DataFrame([],columns=list(X.columns)+[\"Fall\"]+[\"output\"]+[\"output_prob\"])\n", "df_test"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[34]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["i=0\n", "y_valid_pred = 0*y\n", "valid_acc, valid_pre, valid_recall, valid_roc_auc = list(), list(), list(), list()\n", "for train_index, valid_index in skf.split(X_train, y_train):\n", "    X_train_split, X_valid_split = X_train.iloc[train_index,:], X_train.iloc[valid_index,:]\n", "    y_train_split, y_valid_split = y_train.iloc[train_index], y_train.iloc[valid_index]\n", "    optimize_rounds = True\n", "    early_stopping_rounds = 50\n", "    if optimize_rounds:\n", "        eval_set=[(X_valid_split, y_valid_split)]\n", "        fit_model = model.fit(X_train_split, y_train_split, \n", "                                eval_set=eval_set,\n", "                                eval_metric=metrics.gini_xgb,\n", "                                early_stopping_rounds=early_stopping_rounds,\n", "                                verbose=False)\n", "        \n", "    else:\n", "        fit_model = model.fit(X_train_split, y_train_split)\n", "    pred = fit_model.predict_proba(X_valid_split)[:,1]\n", "    y_valid_pred.iloc[valid_index] = pred\n", "    y_valid_scores = (y_valid_pred.iloc[valid_index] > 0.5)\n", "    \n", "    \n", "    #### SAVE DATA####\n", "    y_true_pd=y_valid_split.to_frame().reset_index(drop=True)\n", "    y_pred_pd=y_valid_scores.apply(lambda x: 1 if x==True else 0).to_frame().reset_index(drop=True).rename(columns={\"Fall\":\"output\"})\n", "    y_pred_prob_pd=pd.DataFrame(pred, columns = [\"output_prob\"])\n", "    \n", "    df_subset=pd.concat([X_valid_split.reset_index(drop=True),y_true_pd,y_pred_pd,y_pred_prob_pd],axis=1)\n", "    \n", "    df_test=df_test.append(df_subset, ignore_index=True)\n", "    ######\n", "    \n", "    ###### Save the metrics ####\n", "    \n", "    df_evaluate_proc=get_df_w_metrics(df_subset,procted_col_name,y_col_name,\"output\")\n", "    df_evaluate_proc.to_csv(PATH+\"model\"+str(i)+\"_\"+procted_col_name+\".csv\")\n", "    \n", "    \n", "    df_evaluate_together=df_subset.copy()\n", "    df_evaluate_together[procted_col_name]=\"all\"\n", "    df_evaluate_all=get_df_w_metrics(df_evaluate_together,procted_col_name,y_col_name,\"output\")\n", "    df_evaluate_all.to_csv(PATH+\"model\"+str(i)+\"_all.csv\")\n", "    \n", "    #############################\n", "    \n", "    \n", "    valid_acc.append(accuracy_score(y_valid_split, y_valid_scores))\n", "    valid_pre.append(precision_score(y_valid_split, y_valid_scores))\n", "    valid_recall.append(recall_score(y_valid_split, y_valid_scores))\n", "    valid_roc_auc.append(roc_auc_score(y_valid_split, y_valid_pred.iloc[valid_index]))\n", "    \n", "    i=i+1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Save all data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[35]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_test.to_csv(PATH+\"all_test_data.csv\")\n", "print(\"The full test data lies here:\",PATH+\"all_test_data.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Evaluate"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[36]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = model.predict(X_test)\n", "y_proba = model.predict_proba(X_test)[:,1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[37]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ile_writer.write_cm_plot(y_test, y_pred, cfg.REPORTS_PLOTS_DIR,"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                       # f'{case.lower()}_xgb_cm.pdf', case)\n", "#file_writer.write_joblib(model, model_dir, f'{case.lower()}_xgboost.joblib')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Scores for XGBoost model:\")\n", "print(f\"Accuracy: {np.around(accuracy_score(y_test, y_pred), decimals=3)}\")\n", "print(f\"Precision: {np.around(precision_score(y_test, y_pred), decimals=3)}\")\n", "print(f\"Recall: {np.around(recall_score(y_test, y_pred), decimals=3)}\")\n", "print(f\"ROC AUC: {np.around(roc_auc_score(y_test, y_proba), decimals=3)}\\n\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Save the confusion data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[38]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["column_names = [\"Group\", \"ML\", \"Measure\",\"Value\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_out = pd.DataFrame(columns = column_names)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in [0,1,2,3,4,5,6,7,8,9]:\n", "  \n", "    PATH_loop=PATH+\"model\"+str(i)+\"_all.csv\"\n", "  \n", "    data=pd.read_csv(PATH_loop)\n", "    for group in [\"all\"]:\n", "        for measure in ['FPR', 'FNR', 'ACC', 'F1', 'FDR', 'LRminus','LRplus', 'NPV', 'PPV', 'TNR', 'TPR','TP','TN','FN','FP']:\n", "            value=float(data[data[procted_col_name]==group][measure])\n", "            df_out=df_out.append({'Group': group,\"ML\":\"Xgboost\"+str(i),\"Measure\":measure,\"Value\":value}, ignore_index=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_out.to_csv(PATH+\"/Xgboost_metrics_crossvalidated_all.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[39]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["global_all_bar=sns.barplot(data=df_out[df_out[\"Measure\"].isin([\"FPR\",\"FNR\",\"TPR\",\"TNR\"])],x=\"Group\", y=\"Value\", ci=95,hue=\"Measure\")\n", "global_all_bar.set_title('All')\n", "global_all_bar.get_figure().savefig(PATH_orig+\"/barplot_all.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[40]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["column_names = [\"Group\", \"ML\", \"Measure\",\"Value\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_out = pd.DataFrame(columns = column_names)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in [0,1,2,3,4,5,6,7,8,9]:\n", "    PATH_loop=PATH+\"model\"+str(i)+\"_\"+procted_col_name+\".csv\"\n", "  \n", "    data=pd.read_csv(PATH_loop)\n", "    for group in list(data[procted_col_name].unique()):\n", "        for measure in ['FPR', 'FNR', 'ACC', 'F1', 'FDR', 'LRminus','LRplus', 'NPV', 'PPV', 'TNR', 'TPR','TP','TN','FN','FP']:\n", "            value=float(data[data[procted_col_name]==group][measure])\n", "            df_out=df_out.append({'Group': group,\"ML\":\"Xgboost\"+str(i),\"Measure\":measure,\"Value\":value}, ignore_index=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_out.to_csv(PATH+\"Xgboost_metrics_crossvalidated_\"+procted_col_name+\".csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[41]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["global_proc_bar=sns.barplot(data=df_out[df_out[\"Measure\"].isin([\"FPR\",\"FNR\",\"TPR\",\"TNR\"])],x=\"Group\", y=\"Value\", ci=95,hue=\"Measure\")\n", "global_proc_bar.set_title('Proctected: '+procted_col_name)\n", "global_proc_bar.get_figure().savefig(PATH_orig+\"/barplot_proc.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}