{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ATH=\"/content/drive/My Drive/Kandidat speciale/500 - Notebooks/models/all races_CV50/\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## AIR ### "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["AIR=True"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["file_name=\"Fall_count_clusterOHE_std.csv\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["full_file_path=\"/restricted/s164512/G2020-57-Aalborg-bias/data_air/\"+file_name"]}, {"cell_type": "markdown", "metadata": {}, "source": ["itel_mitigation=\"SHAPoriginal\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["titel_mitigation=\"original\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PATH_orig=\"/restricted/s164512/G2020-57-Aalborg-bias/lau/FFNN_ohe/models/\"+titel_mitigation+\"/\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dropping_D=False\n", "gender_swap=False\n", "DI_remove=False\n", "LFR_mitigation=False #S\u00c3\u00a6t droppingD=True, men ikke fjern den fra X"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_col_name=\"Fall\"\n", "X_col_names=[\n", "'Gender',\n", "'BirthYear',\n", "'LoanPeriod',\n", "'NumberAts',\n", "'Ats_Polstring',\n", "'Ats_Mobilitystokke',\n", "'Ats_Belysning',\n", "'Ats_Underlag',\n", "'Ats_Toiletforh\u00c3\u00b8jereStativ',\n", "'Ats_Signalgivere',\n", "'Ats_EldrevneK\u00c3\u00b8restole',\n", "'Ats_Forst\u00c3\u00b8rrelsesglas',\n", "'Ats_N\u00c3\u00b8dalarmsystemer',\n", "'Ats_MobilePersonl\u00c3\u00b8ftere',\n", "'Ats_TrappelifteMedPlatforme',\n", "'Ats_Badekarsbr\u00c3\u00a6tter',\n", "'Ats_Albuestokke',\n", "'Ats_MaterialerOgRedskaberTilAfm\u00c3\u00a6rkning',\n", "'Ats_Rygl\u00c3\u00a6n',\n", "#'Ats_0',\n", "'Ats_Ganghj\u00c3\u00a6lpemidlerSt\u00c3\u00b8tteTilbeh\u00c3\u00b8r',\n", "'Ats_St\u00c3\u00b8tteb\u00c3\u00b8jler',\n", "'Ats_Lejringspuder',\n", "'Ats_Str\u00c3\u00b8mpep\u00c3\u00a5tagere',\n", "'Ats_D\u00c3\u00b8rtrin',\n", "'Ats_Spil',\n", "'Ats_BordeP\u00c3\u00a5Stole',\n", "'Ats_Drejeskiver',\n", "'Ats_Toiletstole',\n", "'Ats_L\u00c3\u00b8ftereStation\u00c3\u00a6re',\n", "'Ats_Madm\u00c3\u00a5lingshj\u00c3\u00a6lpemidler',\n", "'Ats_Fodbeskyttelse',\n", "'Ats_St\u00c3\u00a5l\u00c3\u00b8ftere',\n", "'Ats_Stole',\n", "'Ats_Sengeborde',\n", "'Ats_Toiletter',\n", "'Ats_Toiletforh\u00c3\u00b8jereFaste',\n", "'Ats_P\u00c3\u00a5kl\u00c3\u00a6dning',\n", "'Ats_Brusere',\n", "'Ats_V\u00c3\u00a6vsskadeLiggende',\n", "'Ats_D\u00c3\u00b8r\u00c3\u00a5bnere',\n", "'Ats_ServeringAfMad',\n", "'Ats_TrappelifteMedS\u00c3\u00a6der',\n", "'Ats_S\u00c3\u00a6derTilMotork\u00c3\u00b8ret\u00c3\u00b8jer',\n", "'Ats_K\u00c3\u00b8restoleManuelleHj\u00c3\u00a6lper',\n", "'Ats_Gangbukke',\n", "'Ats_Rollatorer',\n", "'Ats_Tryks\u00c3\u00a5rsforebyggendeSidde',\n", "'Ats_Fastnettelefoner',\n", "'Ats_B\u00c3\u00a6kkener',\n", "'Ats_Vendehj\u00c3\u00a6lpemidler',\n", "'Ats_Sanseintegration',\n", "'Ats_K\u00c3\u00b8restolsbeskyttere',\n", "'Ats_Arbejdsstole',\n", "'Ats_L\u00c3\u00b8ftesejl',\n", "'Ats_K\u00c3\u00b8restoleForbr\u00c3\u00a6ndingsmotor',\n", "'Ats_L\u00c3\u00b8ftestropper',\n", "'Ats_Stiger',\n", "'Ats_TransportTrapper',\n", "'Ats_DrivaggregaterK\u00c3\u00b8restole',\n", "'Ats_Emballage\u00c3\u00a5bnere',\n", "'Ats_Toiletforh\u00c3\u00b8jereL\u00c3\u00b8se',\n", "'Ats_H\u00c3\u00a5rvask',\n", "'Ats_Personl\u00c3\u00b8ftereStation\u00c3\u00a6re',\n", "'Ats_Madrasser',\n", "'Ats_Vindues\u00c3\u00a5bnere',\n", "'Ats_L\u00c3\u00a6sestativer',\n", "'Ats_K\u00c3\u00b8restoleManuelleDrivringe',\n", "'Ats_S\u00c3\u00a6depuder',\n", "'Ats_UdstyrCykler',\n", "'Ats_Karkludsvridere',\n", "'Ats_Vaskeklude',\n", "'Ats_Sengeudstyr',\n", "'Ats_Madlavningshj\u00c3\u00a6lpemidler',\n", "'Ats_Skohorn',\n", "'Ats_Gribet\u00c3\u00a6ngerManuelle',\n", "'Ats_Hvilestole',\n", "'Ats_EldrevneK\u00c3\u00b8restoleStyring',\n", "'Ats_B\u00c3\u00a6rehj\u00c3\u00a6lpemidlerTilK\u00c3\u00b8restole',\n", "'Ats_L\u00c3\u00b8ftegalgerSeng',\n", "'Ats_H\u00c3\u00b8reforst\u00c3\u00a6rkere',\n", "'Ats_Kalendere',\n", "'Ats_Stokke',\n", "'Ats_L\u00c3\u00b8ftegalger',\n", "'Ats_Ure',\n", "'Ats_St\u00c3\u00b8ttegrebFlytbare',\n", "'Ats_Forflytningsplatforme',\n", "'Ats_RamperFaste',\n", "'Ats_Rygehj\u00c3\u00a6lpemidler',\n", "'Ats_Personv\u00c3\u00a6gte',\n", "'Ats_Man\u00c3\u00b8vreringshj\u00c3\u00a6lpemidler',\n", "'Ats_Overt\u00c3\u00b8j',\n", "'Ats_Lydoptagelse',\n", "'Ats_Gangborde',\n", "'Ats_St\u00c3\u00a5st\u00c3\u00b8ttestole',\n", "'Ats_RamperMobile',\n", "'Ats_B\u00c3\u00a6rehj\u00c3\u00a6lpemidler',\n", "'Ats_Badekarss\u00c3\u00a6der',\n", "'Ats_Siddemodulsystemer',\n", "'Ats_Videosystemer',\n", "'Ats_Siddepuder',\n", "'Ats_Sengeheste',\n", "'Ats_Stolerygge',\n", "'Ats_Rulleborde',\n", "'Ats_Sengeforl\u00c3\u00a6ngere',\n", "'Ats_Madningsudstyr',\n", "'Ats_Brusestole',\n", "'Ats_Flerpunktsstokke',\n", "'Ats_SengebundeMedMotor',\n", "'Ats_Cykler',\n", "'Ats_CykelenhederK\u00c3\u00b8restole',\n", "'Ats_Stokkeholdere',\n", "'Ats_Toiletarmst\u00c3\u00b8tter',\n", "'Ats_Coxitstole',\n", "'Ats_Toilets\u00c3\u00a6der',\n", "'Ats_Rebstiger',\n", "'Ats_Forh\u00c3\u00b8jerklodser',\n", "'Cluster_0',\n", "'Cluster_1',\n", "'Cluster_2',\n", "'Cluster_3',\n", "'Cluster_4',\n", "'Cluster_5',\n", "'Cluster_6',\n", "'Cluster_7',\n", "'Cluster_8',\n", "'Cluster_9',\n", "'Cluster_10',\n", "'Cluster_11',\n", "'Cluster_12',\n", "'Cluster_13',\n", "'Cluster_14',\n", "'Cluster_15',\n", "'Cluster_16',\n", "'Cluster_17',\n", "'Cluster_18',\n", "'Cluster_19']\n", "#X_col_names = [col for col in X_col_names if col not in leave_out ]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["procted_col_name=\"Gender\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### COMPASS ####"]}, {"cell_type": "markdown", "metadata": {}, "source": ["IR=False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["itel_mitigation=\"testCOMPAS\"<br>\n", "ATH_orig=\"/restricted/s164512/G2020-57-Aalborg-bias/lau/FFNN/models/\"+titel_mitigation+\"/\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["ull_file_path = 'https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_col_name=\"is_recid\"<br>\n", "_col_names=['remember_index','sex','age','race', 'juv_fel_count','juv_misd_count','juv_other_count','priors_count',\"c_charge_desc\",\"c_charge_degree\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rocted_col_name=\"race\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def LFR_custom(df_train,y_train,lfr=None):\n", "    from aif360.algorithms.preprocessing import LFR\n", "    from aif360.datasets import BinaryLabelDataset\n", "    \n", "    df_train=pd.concat([df_train,y_train],axis=1)\n", "    \n", "    X_col_names_f=['Gender', 'BirthYear', 'LoanPeriod', 'NumberAts']\n", "    df2_all=df_train.drop(columns=X_col_names_f).copy() #Gemmer alle kolonner, undtagen numerical og gender\n", "    df2=df_train[X_col_names_f+[\"Fall\"]].copy() #Gem kun numerical features\n", "    df2_gender=df_train[\"Gender\"].copy() #Gemmer bare gender\n", "    \n", "    \n", "    #Create the binarylabeldataset\n", "    df_BLD = BinaryLabelDataset(favorable_label='1',\n", "                                unfavorable_label='0',\n", "                                df=df2,\n", "                                label_names=['Fall'],\n", "                                protected_attribute_names=[\"Gender\"],\n", "                                unprivileged_protected_attributes=['0'])\n", "    #Define the DI remover\n", "    if lfr is None:\n", "        lfr = LFR(privileged_groups=[{\"Gender\": 1}], \n", "                                    unprivileged_groups=[{\"Gender\": 0}])\n", "        rp_df = lfr.fit_transform(df_BLD)\n", "    else:\n", "        rp_df = lfr.transform(df_BLD)\n", "        \n\n", "    #Save the columnnames\n", "    all_col_names=df_BLD.feature_names+df_BLD.label_names\n", "        \n", "        \n", "    \n", "    #Save repaired data as pandas DF\n", "    rp_df_pd = pd.DataFrame(np.hstack([rp_df.features,rp_df.labels]),columns=all_col_names) \n", "    \n", "    #Somehow gender is also transformed! So we drop it! DETTE SKAL VI NOK LIGE HOLDE \u00c3\u02dcJE MED\n", "    ###OBS!#####\n", "    rp_df_pd = rp_df_pd.drop(columns=[\"Gender\"])\n", "    #rp_df_pd = pd.concat([rp_df_pd,df2_gender],axis=1)\n\n", "    ##########\n", "    \n", "    \n", "    #Concatenate the non-numerical columns\n", "    transformed_data = pd.concat ([rp_df_pd,df2_all], axis=1)\n", "    \n", "    \n", "    transformed_data=transformed_data.drop(columns=[\"Fall\"])\n", "    \n", "    return transformed_data,lfr"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def DI_remove_custom(df_train,RP_level=1.0):\n", "    from aif360.algorithms.preprocessing import DisparateImpactRemover\n", "    from aif360.datasets import BinaryLabelDataset\n", "    X_col_names_f=['Gender', 'BirthYear', 'LoanPeriod', 'NumberAts']\n", "    df2_all=df_train.drop(columns=X_col_names_f).copy() #Gemmer alle kolonner, undtagen numerical og gender\n", "    df2=df_train[X_col_names_f].copy() #Gem kun numerical features\n", "    \n", "    df2[\"dummy\"]=1 # this is a dummy variable, since DI remover dont use y. \n", "    \n", "    #Create the binarylabeldataset\n", "    df_BLD = BinaryLabelDataset(favorable_label='1',\n", "                                unfavorable_label='0',\n", "                                df=df2,\n", "                                label_names=['dummy'],\n", "                                protected_attribute_names=[\"Gender\"],\n", "                                unprivileged_protected_attributes=['0'])\n", "    #Define the DI remover\n", "    di = DisparateImpactRemover(repair_level=RP_level)\n", "    #Save the columnnames\n", "    all_col_names=df_BLD.feature_names+df_BLD.label_names\n", "    #Reparing the data\n", "    rp_df = di.fit_transform(df_BLD)  \n", "    #Save repaired data as pandas DF\n", "    rp_df_pd = pd.DataFrame(np.hstack([rp_df.features,rp_df.labels]),columns=all_col_names) \n", "    #Concatenate the non-numerical columns\n", "    transformed_data = pd.concat ([rp_df_pd,df2_all], axis=1)\n", "    \n", "    \n", "    transformed_data_train=transformed_data.drop(columns=[\"dummy\"])\n", "    \n", "    return transformed_data_train"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_shape(modelname,model,xcolnames,X_train,X_test,directory,modelnr,plot_type=\"bar\"):\n", "    import shap\n", "   \n", "    if modelname.lower()==\"xgboost\":\n", "        print(\"Using treeexplainer\")\n", "        shap_explainer = shap.TreeExplainer(model, data=X_train)\n", "        shap_values = shap_explainer.shap_values(X_test)\n", "        \n", "    elif modelname.lower()==\"ffnn\":\n", "        print(\"Using deepexplainer\")\n", "        shap_explainer = shap.DeepExplainer(model, data=X_train)\n", "        shap_values = shap_explainer.shap_values(X_test)\n", "    else:\n", "        raise Exception(\"Lau says: Sorry, cant find the model\")\n", "    \n", "    feature_names=xcolnames\n", "    \n", "    #Dette er Christians m\u00c3\u00a5de at hente values fra SHAP\n", "    importance_df  = pd.DataFrame()\n", "    importance_df['feature'] = feature_names\n", "    importance_df['shap_values'] = np.around(np.array(shap_values)[:,:].mean(0), decimals=3)\n", "    importance_df['shap_values_abs'] = np.around(abs(np.array(shap_values)[:,:]).mean(0), decimals=3)\n", "    \n", "    \n", "    if modelname.lower()==\"xgboost\":\n", "        importance_df['feat_imp'] = np.around(model.feature_importances_, decimals=3)\n", "    feat_importance_df_shap = importance_df.groupby('feature').mean().sort_values('shap_values',\n", "                                                                                   ascending=False)\n", "    feat_importance_df_shap = feat_importance_df_shap.reset_index()\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["   \n", "    feat_importance_df_shap.to_csv(directory+modelname+f\"best features model \"+str(modelnr)+\".csv\")\n", "    \n", "    \n", "    ##ALL VALUES###\n", "    \n", "    importance_df_all  = pd.DataFrame(shap_values,columns=feature_names)\n", "    importance_df_all.to_csv(directory+modelname+f\"best features model \"+str(modelnr)+\"_all.csv\")\n", "    \n", "    \n", "    \n", "    file_name_sum = \"shap_summary\"\n", "    file_name_exp = \"shap_row_0\"\n", "  \n", "    \n", "    plt.close()\n", "    shap.summary_plot(shap_values,\n", "                      X_test,\n", "                      feature_names=feature_names,\n", "                      plot_type=plot_type,\n", "                      show=False)\n", "    \n", "    plt.savefig(directory+\"/barplots/\"+modelname+\"shap_plot model\"+str(modelnr)+\".png\",\n", "                bbox_inches = \"tight\")\n", "    \n", "    plt.close()\n", "    shap.summary_plot(shap_values,\n", "                      X_test,\n", "                      feature_names=feature_names,\n", "                      \n", "                      show=False)\n", "    \n", "    plt.savefig(directory+\"/beeplots/\"+modelname+\"shap_plot beeswarm model\"+str(modelnr)+\".png\",\n", "                bbox_inches = \"tight\")\n", "    \n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_nodes=500"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["batch_size=40\n", "epochs=10\n", "p_drop=0.4"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optim_type=\"Adam\" #SGD\n", "lr=0.001 #0.001 er godt\n", "wd=0.05       "]}, {"cell_type": "markdown", "metadata": {}, "source": [".01 er godt til AIR ny!!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[6]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from tqdm.notebook import tqdm\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "#import torchvision.datasets as datasets\n", "from torch.utils.data import DataLoader\n", "#import torchvision.transforms as transforms\n", "import matplotlib.pyplot as plt\n", "import torch.optim as optim\n", "from IPython.display import clear_output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd \n", "import seaborn as sns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "plt.style.use('seaborn')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import plot_confusion_matrix\n", "from sklearn.metrics import confusion_matrix\n", "import matplotlib.patches as mpatches\n", "from matplotlib.patches import Patch\n", "from matplotlib.lines import Line2D"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from sklearn.model_selection import train_test_split\n", "from sklearn import preprocessing"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rom google.colab import drive"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import KFold"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from datetime import datetime"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pytz\n", "import random"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "from sklearn.model_selection import StratifiedKFold"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[7]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utils_Copy import *"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[8]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def loss_fn(target,predictions):\n", "    criterion = nn.BCELoss()\n", "    loss_out = criterion(predictions, target)\n", "    return loss_out"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[9]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def accuracy(true,pred):\n", "    acc = (true.float().round() == pred.float().round()).float().detach().cpu().numpy()\n", "    return float(100 * acc.sum() / len(acc))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_test():\n", "    avg_loss_ts = 0\n", "    avg_acc_ts=0\n", "    model.eval()  # train mode\n", "    for X_batch, Y_batch in data_ts:\n", "        X_batch = X_batch.to(device)\n", "        Y_batch = Y_batch.to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        # forward\n", "        Y_pred = model(X_batch.float()) \n", "        loss = loss_fn(Y_batch.float(), Y_pred.squeeze()) \n\n", "        # calculate metrics to show the user\n", "        avg_loss_ts += loss / len(data_ts)\n", "        avg_acc_ts+=accuracy(Y_batch,Y_pred.squeeze()) / len(data_ts)\n", "    #toc = time()\n", "    return avg_loss_ts, avg_acc_ts"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_all_time_low(all_time,new_val):\n", "    if all_time>new_val:\n", "        return new_val\n", "    else:\n", "        return all_time\n", "    \n", "def get_all_time_high(all_time,new_val):\n", "    if all_time<new_val:\n", "        return new_val\n", "    else:\n", "        return all_time"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[10]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Network(nn.Module):\n", "    def __init__(self):\n", "        super(Network, self).__init__()\n", "        self.fully_connected1 = nn.Sequential(\n", "            nn.Linear(n_feat,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )\n", "        self.fully_connectednew = nn.Sequential(\n", "            nn.Linear(n_nodes,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )\n", "        self.fully_connectednew1 = nn.Sequential(\n", "            nn.Linear(n_nodes,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )\n", "        self.fully_connectednew2 = nn.Sequential(\n", "            nn.Linear(n_nodes,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )\n", "        self.fully_connectednew3 = nn.Sequential(\n", "            nn.Linear(n_nodes,n_nodes),\n", "            nn.ReLU(),\n", "            nn.BatchNorm1d(n_nodes),\n", "            nn.Dropout(p_drop)\n", "            )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        self.fully_connected2 = nn.Sequential(\n", "            nn.Linear(n_nodes,output_dim),\n", "            #nn.Softmax(dim = 1)\n", "            nn.Sigmoid()\n", "            )\n", "    def forward(self, x):\n", "      #reshaping x so it becomes flat, except for the first dimension (which is the minibatch)\n", "        #x = x.view(x.size(0),-1)\n", "        x = self.fully_connected1(x)\n", "        x = self.fully_connectednew(x)\n", "        x = self.fully_connectednew1(x)\n", "        x = self.fully_connectednew2(x)\n", "        x = self.fully_connectednew3(x)\n", "        x = self.fully_connected2(x)\n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[11]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def custom_create_indexes(df,n,seed,strat=False,y_col=None):\n", "    list_of_index=[]\n", "    \n", "    \n", "    \n", "    if strat==False:\n", "        kf=KFold(n_splits=n, random_state=seed, shuffle=True)\n", "        \n", "        \n", "        for train_index, test_index in kf.split(df):\n", "            list_of_index.append(test_index)\n", "        tr_val_ts_indexes=[\n", "        #[[train],[validate],[test]]\n", "        [[*list_of_index[0],*list_of_index[1],*list_of_index[2]],list_of_index[3],list_of_index[4]],\n", "        [[*list_of_index[4],*list_of_index[0],*list_of_index[1]],list_of_index[2],list_of_index[3]],\n", "        [[*list_of_index[3],*list_of_index[4],*list_of_index[0]],list_of_index[1],list_of_index[2]],\n", "        [[*list_of_index[2],*list_of_index[3],*list_of_index[4]],list_of_index[0],list_of_index[1]],\n", "        [[*list_of_index[1],*list_of_index[2],*list_of_index[3]],list_of_index[4],list_of_index[0]],\n", "        ]\n", "    \n", "    \n", "    \n", "    \n", "    else:\n", "        kf = StratifiedKFold(n_splits=n, random_state=seed, shuffle=True)\n", "    \n", "    \n", "        for train_index, test_index in kf.split(df,df[y_col]):\n", "            list_of_index.append(test_index)\n", "        tr_val_ts_indexes=[\n", "        #[[train],[validate],[test]]\n", "        [[*list_of_index[0],*list_of_index[1],*list_of_index[2]],list_of_index[3],list_of_index[4]],\n", "        [[*list_of_index[4],*list_of_index[0],*list_of_index[1]],list_of_index[2],list_of_index[3]],\n", "        [[*list_of_index[3],*list_of_index[4],*list_of_index[0]],list_of_index[1],list_of_index[2]],\n", "        [[*list_of_index[2],*list_of_index[3],*list_of_index[4]],list_of_index[0],list_of_index[1]],\n", "        [[*list_of_index[1],*list_of_index[2],*list_of_index[3]],list_of_index[4],list_of_index[0]],\n", "        ]\n", "    \n", "    return tr_val_ts_indexes"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[12]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["modelcounter=0\n", "for custom_seed in range(1,11):\n", "    \n", "    torch.manual_seed(custom_seed)\n", "    random.seed(custom_seed)\n", "    np.random.seed(custom_seed)\n", "    \n", "    df2 = pd.read_csv(full_file_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["   \n", "    X=df2[X_col_names]\n", "    if dropping_D==True:\n", "        y=df2[[y_col_name,procted_col_name]]\n", "    else:\n", "        y=df2[[y_col_name]]\n\n", "    #https://stackoverflow.com/questions/11587782/creating-dummy-variables-in-pandas-for-python\n", "    if AIR==False:\n", "        just_dummies=pd.get_dummies(X[['sex',\"race\",\"c_charge_desc\",\"c_charge_degree\"]])\n", "        X = pd.concat([X, just_dummies], axis=1) \n", "        X=X.drop(['sex',\"race\",\"c_charge_desc\",\"c_charge_degree\"] ,axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    \n", "    tr_val_ts_indexes= custom_create_indexes(X,5,custom_seed)\n", "    #tr_val_ts_indexes= custom_create_indexes(df2,5,custom_seed,True,y_col_name) #stratify\n\n", "    #i=0\n", "    for mini_loop in range(len(tr_val_ts_indexes)):\n", "        print(\"Running overall number \"+str(modelcounter))\n", "         \n", "        \n", "        X_train_pd, y_train_pd = X.iloc[tr_val_ts_indexes[mini_loop][0]], y.iloc[tr_val_ts_indexes[mini_loop][0]]\n", "        X_val_pd, y_val_pd = X.iloc[tr_val_ts_indexes[mini_loop][1]], y.iloc[tr_val_ts_indexes[mini_loop][1]]\n", "        X_test_pd, y_test_pd = X.iloc[tr_val_ts_indexes[mini_loop][2]], y.iloc[tr_val_ts_indexes[mini_loop][2]]\n", "        \n", "        \n", "        seedName=\"model\"+str(modelcounter)\n", "        PATH=PATH_orig+seedName+\"/\"\n", "        \n", "        if gender_swap==True:\n", "            X_train_pd_copy=X_train_pd.copy()\n", "            y_train_pd_copy=y_train_pd.copy()\n", "            \n", "            X_train_pd_copy[\"Gender\"]=(X_train_pd_copy[\"Gender\"]-1)*(-1)\n", "            \n", "            X_train_pd=pd.concat([X_train_pd,X_train_pd_copy])\n", "            \n", "            y_train_pd=pd.concat([y_train_pd,y_train_pd_copy])\n", "            \n", "            \n", "            \n", "            \n", "        if DI_remove==True:\n", "            X_train_pd=DI_remove_custom(X_train_pd.reset_index(drop=True))\n", "            X_val_pd=DI_remove_custom(X_val_pd.reset_index(drop=True))\n", "            X_test_pd=DI_remove_custom(X_test_pd.reset_index(drop=True))\n", "            \n", "            y_train_pd=y_train_pd.reset_index(drop=True)\n", "            \n", "            y_val_pd=y_val_pd.reset_index(drop=True)\n", "            \n", "            y_test_pd=y_test_pd.reset_index(drop=True)\n", "            \n", "            \n", "        if LFR_mitigation==True:\n", "            \n", "            \n", "            X_train_pd,lfr=LFR_custom(X_train_pd.reset_index(drop=True),\n", "                                  y_train_pd.reset_index(drop=True).drop(columns=[\"Gender\"]),\n", "                                 lfr=None\n", "                                 )\n", "            X_val_pd,lfr=LFR_custom(X_val_pd.reset_index(drop=True),\n", "                                  y_val_pd.reset_index(drop=True).drop(columns=[\"Gender\"]),\n", "                                 lfr=lfr\n", "                                 )\n", "            X_test_pd,lfr=LFR_custom(X_test_pd.reset_index(drop=True),\n", "                                  y_test_pd.reset_index(drop=True).drop(columns=[\"Gender\"]),\n", "                                 lfr=lfr\n", "                                 )\n", "            \n", "            y_train_pd=y_train_pd.reset_index(drop=True)\n", "            \n", "            y_val_pd=y_val_pd.reset_index(drop=True)\n", "            \n", "            y_test_pd=y_test_pd.reset_index(drop=True)\n", "            \n", "            \n", "            \n", "        X_train, y_train = X_train_pd, y_train_pd\n", "        X_val, y_val = X_val_pd, y_val_pd\n", "        X_test, y_test = X_test_pd, y_test_pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        #Save as numpy array for the DATALOADER (PyTorch)\n", "        \n", "        if LFR_mitigation==True:\n", "            temp_col_name_LFR=[name for name in X_col_names if name not in [\"Gender\"]]\n", "            X_train=np.array(X_train[temp_col_name_LFR])\n", "            y_train=np.array(y_train[y_col_name])\n", "            X_val=np.array(X_val[temp_col_name_LFR])\n", "            y_val=np.array(y_val[y_col_name])\n", "            X_test=np.array(X_test[temp_col_name_LFR])\n", "            y_test=np.array(y_test[y_col_name])\n", "        \n", "        \n", "        else:\n", "            \n", "            X_train=np.array(X_train[X_col_names])\n", "            y_train=np.array(y_train[y_col_name])\n", "            X_val=np.array(X_val[X_col_names])\n", "            y_val=np.array(y_val[y_col_name])\n", "            X_test=np.array(X_test[X_col_names])\n", "            y_test=np.array(y_test[y_col_name])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["       # print(\"X_train shape: {}\".format(X_train.shape))\n", "       # print(\"y_train shape: {}\".format(y_train.shape))\n\n", "        #print(\"X_val shape: {}\".format(X_val.shape))\n", "        #print(\"y_val shape: {}\".format(y_val.shape))\n\n", "        #print(\"X_test shape: {}\".format(X_test.shape))\n", "        #print(\"y_test shape: {}\".format(y_test.shape))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        #n_feat=X_train.shape[1]\n", "        \n", "        if LFR_mitigation==True:\n", "            n_feat=len(X_col_names)-1#minus gender\n", "        \n", "        else:\n", "            n_feat=len(X_col_names)\n", "        \n", "        \n", "        output_dim=1 #binary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        data_tr = DataLoader(list(zip(X_train, y_train)), batch_size=batch_size, shuffle=False)\n", "        data_val = DataLoader(list(zip(X_val, y_val)), batch_size=batch_size, shuffle=False)\n", "        data_ts = DataLoader(list(zip(X_test, y_test)), batch_size=batch_size, shuffle=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "        #device=\"cpu\"\n", "        print(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" \n", "        model1 = Network().to(device)\n", "        model1.load_state_dict(torch.load(PATH+'_FFNN_model_local.pth'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        model1.eval()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        X_train_shap=np.array(X_train)\n", "        X_train_shap=torch.tensor(X_train_shap).to(device).float()\n", "        X_test_shap=np.array(X_test)\n", "        X_test_shap=torch.tensor(X_test_shap).to(device).float()\n", "        create_shape(\"FFNN\",model1,X_col_names,X_train_shap,X_test_shap,\"/restricted/s164512/G2020-57-Aalborg-bias/SHAP/\",modelcounter)\n", "        print(f\"Shap nr {modelcounter} is created \")\n", "        modelcounter=modelcounter+1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}