{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import config as cfg\n",
    "import pandas as pd\n",
    "from tools import file_reader, file_writer, explainer\n",
    "from utility import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import recall_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[2]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFR_custom(df_train,y_train,lfr=None):\n",
    "    from aif360.algorithms.preprocessing import LFR\n",
    "    from aif360.datasets import BinaryLabelDataset\n",
    "    \n",
    "    df_train=pd.concat([df_train,y_train],axis=1)\n",
    "    \n",
    "    X_col_names_f=['Gender', 'BirthYear', 'LoanPeriod', 'NumberAts']\n",
    "    df2_all=df_train.drop(columns=X_col_names_f).copy() #Gemmer alle kolonner, undtagen numerical og gender\n",
    "    df2=df_train[X_col_names_f+[\"Fall\"]].copy() #Gem kun numerical features\n",
    "    df2_gender=df_train[\"Gender\"].copy() #Gemmer bare gender\n",
    "    \n",
    "    \n",
    "    #Create the binarylabeldataset\n",
    "    df_BLD = BinaryLabelDataset(favorable_label='1',\n",
    "                                unfavorable_label='0',\n",
    "                                df=df2,\n",
    "                                label_names=['Fall'],\n",
    "                                protected_attribute_names=[\"Gender\"],\n",
    "                                unprivileged_protected_attributes=['0'])\n",
    "    #Define the DI remover\n",
    "    if lfr is None:\n",
    "        lfr = LFR(privileged_groups=[{\"Gender\": 1}], \n",
    "                                    unprivileged_groups=[{\"Gender\": 0}]\n",
    "                  \n",
    "                 )\n",
    "        rp_df = lfr.fit_transform(df_BLD)\n",
    "    else:\n",
    "        rp_df = lfr.transform(df_BLD)\n",
    "        \n",
    "\n",
    "    #Save the columnnames\n",
    "    all_col_names=df_BLD.feature_names+df_BLD.label_names\n",
    "        \n",
    "        \n",
    "    \n",
    "    #Save repaired data as pandas DF\n",
    "    rp_df_pd = pd.DataFrame(np.hstack([rp_df.features,rp_df.labels]),columns=all_col_names) \n",
    "    \n",
    "    #Somehow gender is also transformed! So we drop it! DETTE SKAL VI NOK LIGE HOLDE Ã˜JE MED\n",
    "    ###OBS!#####\n",
    "    rp_df_pd = rp_df_pd.drop(columns=[\"Gender\"])\n",
    "    #rp_df_pd = pd.concat([rp_df_pd,df2_gender],axis=1)\n",
    "\n",
    "    ##########\n",
    "    \n",
    "    \n",
    "    #Concatenate the non-numerical columns\n",
    "    transformed_data = pd.concat ([rp_df_pd,df2_all], axis=1)\n",
    "    \n",
    "    \n",
    "    transformed_data=transformed_data.drop(columns=[\"Fall\"])\n",
    "    \n",
    "    return transformed_data,lfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DI_remove_custom(df_train,RP_level=1.0,drop_d=False,y_train=None):\n",
    "    from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "    from aif360.datasets import BinaryLabelDataset\n",
    "    \n",
    "    if drop_d:\n",
    "        df_train=pd.concat([df_train,y_train],axis=1)\n",
    "    \n",
    "    X_col_names_f=['Gender', 'BirthYear', 'LoanPeriod', 'NumberAts']\n",
    "    df2_all=df_train.drop(columns=X_col_names_f).copy() #Gemmer alle kolonner, undtagen numerical og gender\n",
    "    df2=df_train[X_col_names_f].copy() #Gem kun numerical features\n",
    "    \n",
    "    df2[\"dummy\"]=1 # this is a dummy variable, since DI remover dont use y. \n",
    "    \n",
    "    #Create the binarylabeldataset\n",
    "    df_BLD = BinaryLabelDataset(favorable_label='1',\n",
    "                                unfavorable_label='0',\n",
    "                                df=df2,\n",
    "                                label_names=['dummy'],\n",
    "                                protected_attribute_names=[\"Gender\"],\n",
    "                                unprivileged_protected_attributes=['0'])\n",
    "    #Define the DI remover\n",
    "    di = DisparateImpactRemover(repair_level=RP_level)\n",
    "    #Save the columnnames\n",
    "    all_col_names=df_BLD.feature_names+df_BLD.label_names\n",
    "    #Reparing the data\n",
    "    rp_df = di.fit_transform(df_BLD)  \n",
    "    #Save repaired data as pandas DF\n",
    "    rp_df_pd = pd.DataFrame(np.hstack([rp_df.features,rp_df.labels]),columns=all_col_names) \n",
    "    #Concatenate the non-numerical columns\n",
    "    transformed_data = pd.concat ([rp_df_pd,df2_all], axis=1)\n",
    "    \n",
    "    \n",
    "    transformed_data_train=transformed_data.drop(columns=[\"dummy\"])\n",
    "    \n",
    "    \n",
    "    if drop_d:\n",
    "        transformed_data_train=transformed_data_train.drop(columns=[\"Gender\"])\n",
    "    \n",
    "    return transformed_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[4]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_Copy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[5]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procted_col_name=\"Gender\"\n",
    "y_col_name=\"Fall\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[6]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathRoot=\"../../Data_air/\"\n",
    "#pathFall=pathRoot+\"DI_removed/Fall_count_clusterOHE_std_RPlevel1.0.csv\"\n",
    "pathFall=pathRoot+\"Fall_count_clusterOHE_std.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(pathFall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[7]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "itel_mitigation=\"nostratify\"<br>\n",
    "itel_mitigation=\"DroppingD\"<br>\n",
    "itel_mitigation=\"Gender Swap\"<br>\n",
    "itel_mitigation=\"DI remove\"<br>\n",
    "itel_mitigation=\"LFR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titel_mitigation=\"DI remove no gender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropping_D=True\n",
    "gender_swap=False\n",
    "DI_remove=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFR_mitigation=False #SÃ¸t dropping_D=True, men uden at fjerne den fra X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_orig=\"/restricted/s164512/G2020-57-Aalborg-bias/lau/Xgboost_ohe/models/\"+titel_mitigation+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=PATH_orig#+seedName+\"/\"\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ake dir to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)\n",
    "    print(\"Created new path!: \",PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[8]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = cfg.FALL_XGB_DIR\n",
    "target_name = \"Fall\"\n",
    "y_col_name=target_name\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATA_DIR = cfg.PROCESSED_DATA_DIR<br>\n",
    "ASES = [\"Complete\", \"Compliance\", \"Fall\", \"Fall_test\"]      <br>\n",
    "f = file_reader.read_csv(DATA_DIR, 'fall_emb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[9]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_col_names=[\n",
    "#'Gender',\n",
    "'BirthYear',\n",
    "'LoanPeriod',\n",
    "'NumberAts',\n",
    "'Ats_Polstring',\n",
    "'Ats_Mobilitystokke',\n",
    "'Ats_Belysning',\n",
    "'Ats_Underlag',\n",
    "'Ats_ToiletforhÃ¸jereStativ',\n",
    "'Ats_Signalgivere',\n",
    "'Ats_EldrevneKÃ¸restole',\n",
    "'Ats_ForstÃ¸rrelsesglas',\n",
    "'Ats_NÃ¸dalarmsystemer',\n",
    "'Ats_MobilePersonlÃ¸ftere',\n",
    "'Ats_TrappelifteMedPlatforme',\n",
    "'Ats_BadekarsbrÃ¦tter',\n",
    "'Ats_Albuestokke',\n",
    "'Ats_MaterialerOgRedskaberTilAfmÃ¦rkning',\n",
    "'Ats_RyglÃ¦n',\n",
    "#'Ats_0',\n",
    "'Ats_GanghjÃ¦lpemidlerStÃ¸tteTilbehÃ¸r',\n",
    "'Ats_StÃ¸ttebÃ¸jler',\n",
    "'Ats_Lejringspuder',\n",
    "'Ats_StrÃ¸mpepÃ¥tagere',\n",
    "'Ats_DÃ¸rtrin',\n",
    "'Ats_Spil',\n",
    "'Ats_BordePÃ¥Stole',\n",
    "'Ats_Drejeskiver',\n",
    "'Ats_Toiletstole',\n",
    "'Ats_LÃ¸ftereStationÃ¦re',\n",
    "'Ats_MadmÃ¥lingshjÃ¦lpemidler',\n",
    "'Ats_Fodbeskyttelse',\n",
    "'Ats_StÃ¥lÃ¸ftere',\n",
    "'Ats_Stole',\n",
    "'Ats_Sengeborde',\n",
    "'Ats_Toiletter',\n",
    "'Ats_ToiletforhÃ¸jereFaste',\n",
    "'Ats_PÃ¥klÃ¦dning',\n",
    "'Ats_Brusere',\n",
    "'Ats_VÃ¦vsskadeLiggende',\n",
    "'Ats_DÃ¸rÃ¥bnere',\n",
    "'Ats_ServeringAfMad',\n",
    "'Ats_TrappelifteMedSÃ¦der',\n",
    "'Ats_SÃ¦derTilMotorkÃ¸retÃ¸jer',\n",
    "'Ats_KÃ¸restoleManuelleHjÃ¦lper',\n",
    "'Ats_Gangbukke',\n",
    "'Ats_Rollatorer',\n",
    "'Ats_TryksÃ¥rsforebyggendeSidde',\n",
    "'Ats_Fastnettelefoner',\n",
    "'Ats_BÃ¦kkener',\n",
    "'Ats_VendehjÃ¦lpemidler',\n",
    "'Ats_Sanseintegration',\n",
    "'Ats_KÃ¸restolsbeskyttere',\n",
    "'Ats_Arbejdsstole',\n",
    "'Ats_LÃ¸ftesejl',\n",
    "'Ats_KÃ¸restoleForbrÃ¦ndingsmotor',\n",
    "'Ats_LÃ¸ftestropper',\n",
    "'Ats_Stiger',\n",
    "'Ats_TransportTrapper',\n",
    "'Ats_DrivaggregaterKÃ¸restole',\n",
    "'Ats_EmballageÃ¥bnere',\n",
    "'Ats_ToiletforhÃ¸jereLÃ¸se',\n",
    "'Ats_HÃ¥rvask',\n",
    "'Ats_PersonlÃ¸ftereStationÃ¦re',\n",
    "'Ats_Madrasser',\n",
    "'Ats_VinduesÃ¥bnere',\n",
    "'Ats_LÃ¦sestativer',\n",
    "'Ats_KÃ¸restoleManuelleDrivringe',\n",
    "'Ats_SÃ¦depuder',\n",
    "'Ats_UdstyrCykler',\n",
    "'Ats_Karkludsvridere',\n",
    "'Ats_Vaskeklude',\n",
    "'Ats_Sengeudstyr',\n",
    "'Ats_MadlavningshjÃ¦lpemidler',\n",
    "'Ats_Skohorn',\n",
    "'Ats_GribetÃ¦ngerManuelle',\n",
    "'Ats_Hvilestole',\n",
    "'Ats_EldrevneKÃ¸restoleStyring',\n",
    "'Ats_BÃ¦rehjÃ¦lpemidlerTilKÃ¸restole',\n",
    "'Ats_LÃ¸ftegalgerSeng',\n",
    "'Ats_HÃ¸reforstÃ¦rkere',\n",
    "'Ats_Kalendere',\n",
    "'Ats_Stokke',\n",
    "'Ats_LÃ¸ftegalger',\n",
    "'Ats_Ure',\n",
    "'Ats_StÃ¸ttegrebFlytbare',\n",
    "'Ats_Forflytningsplatforme',\n",
    "'Ats_RamperFaste',\n",
    "'Ats_RygehjÃ¦lpemidler',\n",
    "'Ats_PersonvÃ¦gte',\n",
    "'Ats_ManÃ¸vreringshjÃ¦lpemidler',\n",
    "'Ats_OvertÃ¸j',\n",
    "'Ats_Lydoptagelse',\n",
    "'Ats_Gangborde',\n",
    "'Ats_StÃ¥stÃ¸ttestole',\n",
    "'Ats_RamperMobile',\n",
    "'Ats_BÃ¦rehjÃ¦lpemidler',\n",
    "'Ats_BadekarssÃ¦der',\n",
    "'Ats_Siddemodulsystemer',\n",
    "'Ats_Videosystemer',\n",
    "'Ats_Siddepuder',\n",
    "'Ats_Sengeheste',\n",
    "'Ats_Stolerygge',\n",
    "'Ats_Rulleborde',\n",
    "'Ats_SengeforlÃ¦ngere',\n",
    "'Ats_Madningsudstyr',\n",
    "'Ats_Brusestole',\n",
    "'Ats_Flerpunktsstokke',\n",
    "'Ats_SengebundeMedMotor',\n",
    "'Ats_Cykler',\n",
    "'Ats_CykelenhederKÃ¸restole',\n",
    "'Ats_Stokkeholdere',\n",
    "'Ats_ToiletarmstÃ¸tter',\n",
    "'Ats_Coxitstole',\n",
    "'Ats_ToiletsÃ¦der',\n",
    "'Ats_Rebstiger',\n",
    "'Ats_ForhÃ¸jerklodser',\n",
    "'Cluster_0',\n",
    "'Cluster_1',\n",
    "'Cluster_2',\n",
    "'Cluster_3',\n",
    "'Cluster_4',\n",
    "'Cluster_5',\n",
    "'Cluster_6',\n",
    "'Cluster_7',\n",
    "'Cluster_8',\n",
    "'Cluster_9',\n",
    "'Cluster_10',\n",
    "'Cluster_11',\n",
    "'Cluster_12',\n",
    "'Cluster_13',\n",
    "'Cluster_14',\n",
    "'Cluster_15',\n",
    "'Cluster_16',\n",
    "'Cluster_17',\n",
    "'Cluster_18',\n",
    "'Cluster_19']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[10]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_5_persons=pd.read_csv(\"/restricted/s164512/G2020-57-Aalborg-bias/6 citizens/6_cit_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ll_cols=X_col_names+[y_col_name]<br>\n",
    "ll_cols=all_cols+[\"output\"]<br>\n",
    "ll_cols=all_cols+[\"output_prob\"]<br>\n",
    "ll_cols=all_cols+[\"Model\"]<br>\n",
    "f_predicted=pd.DataFrame([],columns=all_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[11]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcounter=0\n",
    "df_test=pd.DataFrame([],columns=list(X_col_names)+[\"Fall\"]+[\"output\"]+[\"output_prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LFR_mitigation==True:\n",
    "    df_test.drop(columns=[\"Gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_seed in range(1,11):\n",
    "    \n",
    "    \n",
    "    df = df.sample(frac=1, random_state=new_seed).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "  \n",
    "    X = df[X_col_names]\n",
    "    y = df[target_name].to_frame()\n",
    "    \n",
    "        \n",
    "    \n",
    "    neg, pos = np.bincount(y[target_name])\n",
    "    scale_pos_weight = neg / pos\n",
    "    params = {\"n_estimators\": 400,\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"scale_pos_weight\": scale_pos_weight,\n",
    "            \"use_label_encoder\": False,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"seed\": 0\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    #skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=new_seed)\n",
    "    skf=KFold(n_splits=5, random_state=new_seed, shuffle=True)\n",
    "    \n",
    "    y_valid_pred = 0*y[target_name]\n",
    "    valid_acc, valid_pre, valid_recall, valid_roc_auc = list(), list(), list(), list()\n",
    "    #for train_index, valid_index in skf.split(X_train, y_train):\n",
    "    for train_index, valid_index in skf.split(X):\n",
    "        print(f\"Running model {modelcounter}\")\n",
    "        #X_train_split, X_valid_split = X_train.iloc[train_index,:], X_train.iloc[valid_index,:]\n",
    "        #y_train_split, y_valid_split = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "        \n",
    "        \n",
    "        X_train_split, X_valid_split = X.iloc[train_index,:], X.iloc[valid_index,:]\n",
    "        y_train_split, y_valid_split = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        if gender_swap==True:\n",
    "            X_train_split_copy=X_train_split.copy()\n",
    "            y_train_split_copy=y_train_split.copy()\n",
    "            \n",
    "            X_train_split_copy[\"Gender\"]=(X_train_split_copy[\"Gender\"]-1)*(-1)\n",
    "            \n",
    "            X_train_split=pd.concat([X_train_split,X_train_split_copy])\n",
    "            \n",
    "            y_train_split=pd.concat([y_train_split,y_train_split_copy])\n",
    "            \n",
    "        if DI_remove==True:\n",
    "            X_train_split=DI_remove_custom(X_train_split.reset_index(drop=True),drop_d=dropping_D,y_train=df[procted_col_name].iloc[train_index].to_frame().reset_index(drop=True))\n",
    "            X_valid_split=DI_remove_custom(X_valid_split.reset_index(drop=True),drop_d=dropping_D,y_train=df[procted_col_name].iloc[valid_index].to_frame().reset_index(drop=True))\n",
    "            \n",
    "        if LFR_mitigation==True:\n",
    "            X_train_split,lfr=LFR_custom(X_train_split.reset_index(drop=True),\n",
    "                                         y_train_split.reset_index(drop=True),\n",
    "                                         lfr=None)\n",
    "            X_valid_split,lfr=LFR_custom(X_valid_split.reset_index(drop=True),\n",
    "                                         y_valid_split.reset_index(drop=True),\n",
    "                                         lfr)\n",
    "            \n",
    "        \n",
    "        optimize_rounds = True\n",
    "        early_stopping_rounds = 50\n",
    "        if optimize_rounds:\n",
    "            eval_set=[(X_valid_split, y_valid_split)]\n",
    "            fit_model = model.fit(X_train_split, y_train_split, \n",
    "                                    eval_set=eval_set,\n",
    "                                    eval_metric=metrics.gini_xgb,\n",
    "                                    early_stopping_rounds=early_stopping_rounds,\n",
    "                                    verbose=False)\n",
    "        else:\n",
    "            fit_model = model.fit(X_train_split, y_train_split)\n",
    "        pred = fit_model.predict_proba(X_valid_split)[:,1]\n",
    "        y_valid_pred.iloc[valid_index] = pred\n",
    "        y_valid_scores = (y_valid_pred.iloc[valid_index] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #### SAVE DATA####\n",
    "        y_true_pd=y_valid_split.reset_index(drop=True)\n",
    "        #y_true_pd=y_valid_split.to_frame().reset_index(drop=True)\n",
    "        y_pred_pd=y_valid_scores.apply(lambda x: 1 if x==True else 0).to_frame().reset_index(drop=True).rename(columns={\"Fall\":\"output\"})\n",
    "        y_pred_prob_pd=pd.DataFrame(pred, columns = [\"output_prob\"])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        df_subset=pd.concat([X_valid_split.reset_index(drop=True),y_true_pd,y_pred_pd,y_pred_prob_pd],axis=1)\n",
    "        \n",
    "        \n",
    "        if dropping_D==True:\n",
    "            df_subset[procted_col_name]=list(df[procted_col_name].iloc[valid_index])\n",
    "        \n",
    "        df_subset[\"Model\"]=\"Model\"+str(modelcounter)\n",
    "        \n",
    "        df_subset.to_csv(PATH+\"model\"+str(modelcounter)+\"_test_data.csv\")\n",
    "        df_test=df_test.append(df_subset, ignore_index=True)\n",
    "        ######\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##SAVE 6 persons#\n",
    "  \n",
    "        #df_predicted_subset=df_5_persons.copy().drop(columns=[\"Unnamed: 0\"])\n",
    "    \n",
    "        #X_numpy=np.array(df_predicted_subset[X_col_names])\n",
    "        #pred_6cit = fit_model.predict_proba(X_numpy)[:,1]\n",
    "        \n",
    "        #y_valid_scores_6cit = pred_6cit>0.5\n",
    "        #y_valid_scores_6cit=pd.DataFrame(y_valid_scores_6cit,columns=[\"prob\"])\n",
    "        \n",
    "        \n",
    "        #y_pred_pd_6cit=y_valid_scores_6cit.rename(columns={\"prob\":\"output\"})[\"output\"].apply(lambda x: 1 if x==True else 0).to_frame()#.rename(columns={\"prob\":\"output\"})\n",
    "        #y_pred_prob_pd_6cit=pd.DataFrame(pred_6cit, columns = [\"output_prob\"])\n",
    "                \n",
    "        \n",
    "\n",
    "        #df_predicted_subset=pd.concat([df_predicted_subset[X_col_names+[y_col_name]].reset_index(drop=True),y_pred_pd_6cit,y_pred_prob_pd_6cit],axis=1)\n",
    "        #df_predicted_subset[\"Model\"]=\"Model\"+str(modelcounter)\n",
    "\n",
    "        #df_predicted_subset=df_predicted_subset.reset_index(drop=True)\n",
    "\n",
    "        #df_predicted=pd.concat([df_predicted,df_predicted_subset],axis=0,sort=False)\n",
    "        \n",
    "        ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        valid_acc.append(accuracy_score(y_valid_split, y_valid_scores))\n",
    "        valid_pre.append(precision_score(y_valid_split, y_valid_scores))\n",
    "        valid_recall.append(recall_score(y_valid_split, y_valid_scores))\n",
    "        valid_roc_auc.append(roc_auc_score(y_valid_split, y_valid_pred.iloc[valid_index]))\n",
    "        modelcounter=modelcounter+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[13]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(PATH+\"all_test_data.csv\")\n",
    "print(\"The full test data lies here:\",PATH+\"all_test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save 6 persons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[13]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_predicted.to_csv(\"/restricted/s164512/G2020-57-Aalborg-bias/6 citizens/Xgboost_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[14]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_pred = model.predict(X_test)<br>\n",
    "_proba = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[15]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ile_writer.write_cm_plot(y_test, y_pred, cfg.REPORTS_PLOTS_DIR,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                       # f'{case.lower()}_xgb_cm.pdf', case)\n",
    "#file_writer.write_joblib(model, model_dir, f'{case.lower()}_xgboost.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rint(f\"Scores for XGBoost model:\")<br>\n",
    "rint(f\"Accuracy: {np.around(accuracy_score(y_test, y_pred), decimals=3)}\")<br>\n",
    "rint(f\"Precision: {np.around(precision_score(y_test, y_pred), decimals=3)}\")<br>\n",
    "rint(f\"Recall: {np.around(recall_score(y_test, y_pred), decimals=3)}\")<br>\n",
    "rint(f\"ROC AUC: {np.around(roc_auc_score(y_test, y_proba), decimals=3)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the confusion data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[16]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "olumn_names = [\"Group\", \"ML\", \"Measure\",\"Value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_out = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or i in range(50):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#    PATH_loop=PATH+\"model\"+str(i)+\"_all.csv\"\n",
    "  \n",
    "#    data=pd.read_csv(PATH_loop)\n",
    "#    for group in [\"all\"]:\n",
    "#        for measure in ['FPR', 'FNR', 'ACC', 'F1', 'FDR', 'LRminus','LRplus', 'NPV', 'PPV', 'TNR', 'TPR','TP','TN','FN','FP',\"y_hat_mean\",\"y_target_mean\",\"y_hat_prob\"]:\n",
    "#            value=float(data[data[procted_col_name]==group][measure])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           df_out=df_out.append({'Group': group,\"ML\":\"Xgboost\"+str(i),\"Measure\":measure,\"Value\":value}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_out.to_csv(PATH+\"/Xgboost_metrics_crossvalidated_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[17]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lobal_all_bar=sns.barplot(data=df_out[df_out[\"Measure\"].isin([\"FPR\",\"FNR\",\"TPR\",\"TNR\"])],x=\"Group\", y=\"Value\", ci=95,hue=\"Measure\")<br>\n",
    "lobal_all_bar.set_title('All')<br>\n",
    "lobal_all_bar.get_figure().savefig(PATH_orig+\"/barplot_all.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[18]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "olumn_names = [\"Group\", \"ML\", \"Measure\",\"Value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_out = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or i in range(50):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   PATH_loop=PATH+\"model\"+str(i)+\"_\"+procted_col_name+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#    data=pd.read_csv(PATH_loop)\n",
    "#    for group in list(data[procted_col_name].unique()):\n",
    "#        for measure in ['FPR', 'FNR', 'ACC', 'F1', 'FDR', 'LRminus','LRplus', 'NPV', 'PPV', 'TNR', 'TPR','TP','TN','FN','FP',\"y_hat_mean\",\"y_target_mean\",\"y_hat_prob\"]:\n",
    "#            value=float(data[data[procted_col_name]==group][measure])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           df_out=df_out.append({'Group': group,\"ML\":\"Xgboost\"+str(i),\"Measure\":measure,\"Value\":value}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_out.to_csv(PATH+\"Xgboost_metrics_crossvalidated_\"+procted_col_name+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[19]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lobal_proc_bar=sns.barplot(data=df_out[df_out[\"Measure\"].isin([\"FPR\",\"FNR\",\"TPR\",\"TNR\"])],x=\"Group\", y=\"Value\", ci=95,hue=\"Measure\")<br>\n",
    "lobal_proc_bar.set_title('Proctected: '+procted_col_name)#<br>\n",
    "lobal_proc_bar.get_figure().savefig(PATH_orig+\"/barplot_proc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[20]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df[procted_col_name].iloc[valid_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
